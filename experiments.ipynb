{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-18T09:06:03.917318Z",
     "start_time": "2025-06-18T09:06:03.906641Z"
    }
   },
   "source": [
    "import source.prepare_data as prd\n",
    "import source.dataset as dat\n",
    "import source.multi_layer_perceptron as mlp\n",
    "import source.table as tb\n",
    "import source.comparision as comp\n",
    "import source.recurent_neural_networks as rnn"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T08:59:21.581680Z",
     "start_time": "2025-06-18T08:59:21.027518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from importlib import reload\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ],
   "id": "ca71a5bfb335e1dd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T08:59:25.499356Z",
     "start_time": "2025-06-18T08:59:25.485850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reload(prd)\n",
    "reload(dat)\n",
    "reload(mlp)\n",
    "reload(tb)\n",
    "reload(comp)"
   ],
   "id": "c33b1c36416cdd72",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'source.comparision' from 'C:\\\\Python_files\\\\DL_final2\\\\source\\\\comparision.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T08:59:31.655392Z",
     "start_time": "2025-06-18T08:59:29.483786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "1) Preprocessing\n",
    "\"\"\"\n",
    "# load models and dataset\n",
    "df = pd.read_csv(\"hf://datasets/gxb912/large-twitter-tweets-sentiment/train.csv\", nrows=100)\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "id": "ff9071c6d688266f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T08:59:34.462754Z",
     "start_time": "2025-06-18T08:59:33.956145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prepare dataset\n",
    "df = prd.prepare_df(df, nlp)\n",
    "\n",
    "# create dataset out of cleaned columns\n",
    "dataset = dat.Text_Dataset(df, col_text=\"clean_text_str\", col_label=\"sentiment\", args={\"max_features\":5000})\n",
    "dataset.split_dataset()\n"
   ],
   "id": "1d7e7f4ea60b4906",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T09:14:06.558639Z",
     "start_time": "2025-06-18T09:14:02.155524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_TF, X_test_TF, Y_train_TF, Y_test_TF = dataset.get_encodings(tdidf=True)\n",
    "\n",
    "mlp_tdidf_params = mlp.find_best_mlp(X_train=X_train_TF,\n",
    "                                     Y_train=Y_train_TF,\n",
    "                                     X_test=X_test_TF,\n",
    "                                     Y_test=Y_test_TF,\n",
    "                                     n_trials=7)"
   ],
   "id": "3fcc303b3976a8d3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 11:14:02,159] A new study created in memory with name: mlp_optimization\n",
      "[I 2025-06-18 11:14:02,696] Trial 0 finished with values: [0.7039019465446472, 0.550000011920929] and parameters: {'epochs': 109, 'learning_rate': 0.0010090673382862306, 'units': 3}.\n",
      "[I 2025-06-18 11:14:03,341] Trial 1 finished with values: [0.6907943487167358, 0.550000011920929] and parameters: {'epochs': 163, 'learning_rate': 0.06006648508660184, 'units': 6}.\n",
      "[I 2025-06-18 11:14:04,003] Trial 2 finished with values: [0.6870597004890442, 0.550000011920929] and parameters: {'epochs': 176, 'learning_rate': 0.07127834039503608, 'units': 3}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 112 calls to <function Model.make_test_function.<locals>.test_function at 0x000001C21CCE0A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 11:14:04,614] Trial 3 finished with values: [0.6890912055969238, 0.6000000238418579] and parameters: {'epochs': 157, 'learning_rate': 0.4432711175250896, 'units': 5}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 113 calls to <function Model.make_test_function.<locals>.test_function at 0x000001C2252CB130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 11:14:05,182] Trial 4 finished with values: [0.6768187284469604, 0.6000000238418579] and parameters: {'epochs': 134, 'learning_rate': 0.363623490990438, 'units': 4}.\n",
      "[I 2025-06-18 11:14:05,842] Trial 5 finished with values: [0.7047067880630493, 0.6000000238418579] and parameters: {'epochs': 179, 'learning_rate': 0.44668373973352304, 'units': 3}.\n",
      "[I 2025-06-18 11:14:06,540] Trial 6 finished with values: [0.6830264329910278, 0.5] and parameters: {'epochs': 197, 'learning_rate': 0.3417516190769708, 'units': 5}.\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T09:14:09.922165Z",
     "start_time": "2025-06-18T09:14:09.199853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mlp_tdidf = mlp.Feedforward_Model(X_train_TF, Y_train_TF, units=mlp_tdidf_params.iloc[-1]['params_units']) # the last one is the best one\n",
    "mlp_tdidf.train(LR=mlp_tdidf_params.iloc[-1]['params_learning_rate'], epochs=mlp_tdidf_params.iloc[-1]['params_epochs'])\n",
    "mlp_tdidf.plot_loss_accuracy()"
   ],
   "id": "51bae710fa8c52c7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T09:14:38.542226Z",
     "start_time": "2025-06-18T09:14:13.616696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_EBM, X_test_EBM, Y_train_EBM, Y_test_EBM = dataset.get_sequences(vocab_size=1000, maxlen=10)\n",
    "rnn_emb_params = rnn.find_best_rnn(X_train_EBM, Y_train_EBM, X_test_EBM, Y_test_EBM, n_trials=7)"
   ],
   "id": "f84e7a8da037a8a8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 11:14:13,675] A new study created in memory with name: mlp_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 0.7008 - accuracy: 0.3750 - val_loss: 0.7343 - val_accuracy: 0.5000\n",
      "Epoch 2/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6587 - accuracy: 0.5781 - val_loss: 0.7443 - val_accuracy: 0.5000\n",
      "Epoch 3/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5824 - accuracy: 0.7344 - val_loss: 0.8293 - val_accuracy: 0.3750\n",
      "Epoch 4/125\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4963 - accuracy: 0.8125 - val_loss: 0.9493 - val_accuracy: 0.3750\n",
      "Epoch 5/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3617 - accuracy: 0.9219 - val_loss: 1.1110 - val_accuracy: 0.3750\n",
      "Epoch 6/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2796 - accuracy: 0.9219 - val_loss: 1.0833 - val_accuracy: 0.5000\n",
      "Epoch 7/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2579 - accuracy: 0.9375 - val_loss: 1.1701 - val_accuracy: 0.5000\n",
      "Epoch 8/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3299 - accuracy: 0.9062 - val_loss: 1.3216 - val_accuracy: 0.5000\n",
      "Epoch 9/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1945 - accuracy: 0.9531 - val_loss: 1.8638 - val_accuracy: 0.3750\n",
      "Epoch 10/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1856 - accuracy: 0.9531 - val_loss: 1.9951 - val_accuracy: 0.3750\n",
      "Epoch 11/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1844 - accuracy: 0.9531 - val_loss: 2.1463 - val_accuracy: 0.3750\n",
      "Epoch 12/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1915 - accuracy: 0.9531 - val_loss: 2.4002 - val_accuracy: 0.3750\n",
      "Epoch 13/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1919 - accuracy: 0.9531 - val_loss: 2.5534 - val_accuracy: 0.3750\n",
      "Epoch 14/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1990 - accuracy: 0.9531 - val_loss: 2.6737 - val_accuracy: 0.3125\n",
      "Epoch 15/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2024 - accuracy: 0.9531 - val_loss: 2.7833 - val_accuracy: 0.3125\n",
      "Epoch 16/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2036 - accuracy: 0.9531 - val_loss: 2.8522 - val_accuracy: 0.3125\n",
      "Epoch 17/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2027 - accuracy: 0.9531 - val_loss: 2.8735 - val_accuracy: 0.3125\n",
      "Epoch 18/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2004 - accuracy: 0.9531 - val_loss: 2.8512 - val_accuracy: 0.3125\n",
      "Epoch 19/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1967 - accuracy: 0.9531 - val_loss: 2.7829 - val_accuracy: 0.3125\n",
      "Epoch 20/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1993 - accuracy: 0.9531 - val_loss: 2.7886 - val_accuracy: 0.3125\n",
      "Epoch 21/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1964 - accuracy: 0.9531 - val_loss: 2.7989 - val_accuracy: 0.3125\n",
      "Epoch 22/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1950 - accuracy: 0.9531 - val_loss: 2.7846 - val_accuracy: 0.3125\n",
      "Epoch 23/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1947 - accuracy: 0.9531 - val_loss: 2.7542 - val_accuracy: 0.3125\n",
      "Epoch 24/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1937 - accuracy: 0.9531 - val_loss: 2.7137 - val_accuracy: 0.3125\n",
      "Epoch 25/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1923 - accuracy: 0.9531 - val_loss: 2.6674 - val_accuracy: 0.3125\n",
      "Epoch 26/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1905 - accuracy: 0.9531 - val_loss: 2.6180 - val_accuracy: 0.3125\n",
      "Epoch 27/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1886 - accuracy: 0.9531 - val_loss: 2.5678 - val_accuracy: 0.3125\n",
      "Epoch 28/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1865 - accuracy: 0.9531 - val_loss: 2.5182 - val_accuracy: 0.3125\n",
      "Epoch 29/125\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1842 - accuracy: 0.9531 - val_loss: 2.4702 - val_accuracy: 0.3125\n",
      "Epoch 30/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1819 - accuracy: 0.9531 - val_loss: 2.4238 - val_accuracy: 0.3125\n",
      "Epoch 31/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1796 - accuracy: 0.9531 - val_loss: 2.3789 - val_accuracy: 0.3125\n",
      "Epoch 32/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1774 - accuracy: 0.9531 - val_loss: 2.3346 - val_accuracy: 0.3125\n",
      "Epoch 33/125\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1756 - accuracy: 0.9531 - val_loss: 2.2903 - val_accuracy: 0.3125\n",
      "Epoch 34/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1742 - accuracy: 0.9531 - val_loss: 2.2451 - val_accuracy: 0.3125\n",
      "Epoch 35/125\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1733 - accuracy: 0.9531 - val_loss: 2.1987 - val_accuracy: 0.3125\n",
      "Epoch 36/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1729 - accuracy: 0.9531 - val_loss: 2.1512 - val_accuracy: 0.3125\n",
      "Epoch 37/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1727 - accuracy: 0.9531 - val_loss: 2.1037 - val_accuracy: 0.3125\n",
      "Epoch 38/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1726 - accuracy: 0.9531 - val_loss: 2.0585 - val_accuracy: 0.3125\n",
      "Epoch 39/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1726 - accuracy: 0.9531 - val_loss: 2.0187 - val_accuracy: 0.3125\n",
      "Epoch 40/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1725 - accuracy: 0.9531 - val_loss: 1.9882 - val_accuracy: 0.3125\n",
      "Epoch 41/125\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1725 - accuracy: 0.9531 - val_loss: 1.9699 - val_accuracy: 0.3125\n",
      "Epoch 42/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1727 - accuracy: 0.9531 - val_loss: 1.9655 - val_accuracy: 0.3125\n",
      "Epoch 43/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1728 - accuracy: 0.9531 - val_loss: 1.9747 - val_accuracy: 0.3125\n",
      "Epoch 44/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1726 - accuracy: 0.9531 - val_loss: 1.9958 - val_accuracy: 0.3125\n",
      "Epoch 45/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1722 - accuracy: 0.9531 - val_loss: 2.0254 - val_accuracy: 0.3125\n",
      "Epoch 46/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1717 - accuracy: 0.9531 - val_loss: 2.0598 - val_accuracy: 0.3125\n",
      "Epoch 47/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1712 - accuracy: 0.9531 - val_loss: 2.0955 - val_accuracy: 0.3125\n",
      "Epoch 48/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1708 - accuracy: 0.9531 - val_loss: 2.1298 - val_accuracy: 0.3125\n",
      "Epoch 49/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1704 - accuracy: 0.9531 - val_loss: 2.1615 - val_accuracy: 0.3125\n",
      "Epoch 50/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1700 - accuracy: 0.9531 - val_loss: 2.1902 - val_accuracy: 0.3125\n",
      "Epoch 51/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1697 - accuracy: 0.9531 - val_loss: 2.2165 - val_accuracy: 0.3125\n",
      "Epoch 52/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1696 - accuracy: 0.9531 - val_loss: 2.2412 - val_accuracy: 0.3125\n",
      "Epoch 53/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1695 - accuracy: 0.9531 - val_loss: 2.2647 - val_accuracy: 0.3125\n",
      "Epoch 54/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1696 - accuracy: 0.9531 - val_loss: 2.2873 - val_accuracy: 0.3125\n",
      "Epoch 55/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1696 - accuracy: 0.9531 - val_loss: 2.3089 - val_accuracy: 0.3125\n",
      "Epoch 56/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1697 - accuracy: 0.9531 - val_loss: 2.3285 - val_accuracy: 0.3125\n",
      "Epoch 57/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1697 - accuracy: 0.9531 - val_loss: 2.3452 - val_accuracy: 0.3125\n",
      "Epoch 58/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1697 - accuracy: 0.9531 - val_loss: 2.3581 - val_accuracy: 0.3125\n",
      "Epoch 59/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1698 - accuracy: 0.9531 - val_loss: 2.3662 - val_accuracy: 0.3125\n",
      "Epoch 60/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1697 - accuracy: 0.9531 - val_loss: 2.3693 - val_accuracy: 0.3125\n",
      "Epoch 61/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1697 - accuracy: 0.9531 - val_loss: 2.3673 - val_accuracy: 0.3125\n",
      "Epoch 62/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1696 - accuracy: 0.9531 - val_loss: 2.3611 - val_accuracy: 0.3125\n",
      "Epoch 63/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1695 - accuracy: 0.9531 - val_loss: 2.3518 - val_accuracy: 0.3125\n",
      "Epoch 64/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1694 - accuracy: 0.9531 - val_loss: 2.3408 - val_accuracy: 0.3125\n",
      "Epoch 65/125\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1693 - accuracy: 0.9531 - val_loss: 2.3295 - val_accuracy: 0.3125\n",
      "Epoch 66/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1693 - accuracy: 0.9531 - val_loss: 2.3191 - val_accuracy: 0.3125\n",
      "Epoch 67/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1692 - accuracy: 0.9531 - val_loss: 2.3105 - val_accuracy: 0.3125\n",
      "Epoch 68/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1692 - accuracy: 0.9531 - val_loss: 2.3039 - val_accuracy: 0.3125\n",
      "Epoch 69/125\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1692 - accuracy: 0.9531 - val_loss: 2.2994 - val_accuracy: 0.3125\n",
      "Epoch 70/125\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1692 - accuracy: 0.9531 - val_loss: 2.2965 - val_accuracy: 0.3125\n",
      "Epoch 71/125\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1692 - accuracy: 0.9531 - val_loss: 2.2946 - val_accuracy: 0.3125\n",
      "Epoch 72/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1692 - accuracy: 0.9531 - val_loss: 2.2936 - val_accuracy: 0.3125\n",
      "Epoch 73/125\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1692 - accuracy: 0.9531 - val_loss: 2.2933 - val_accuracy: 0.3125\n",
      "Epoch 74/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1692 - accuracy: 0.9531 - val_loss: 2.2939 - val_accuracy: 0.3125\n",
      "Epoch 75/125\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1692 - accuracy: 0.9531 - val_loss: 2.2959 - val_accuracy: 0.3125\n",
      "Epoch 76/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1692 - accuracy: 0.9531 - val_loss: 2.2996 - val_accuracy: 0.3125\n",
      "Epoch 77/125\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1692 - accuracy: 0.9531 - val_loss: 2.3053 - val_accuracy: 0.3125\n",
      "Epoch 78/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1692 - accuracy: 0.9531 - val_loss: 2.3129 - val_accuracy: 0.3125\n",
      "Epoch 79/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1691 - accuracy: 0.9531 - val_loss: 2.3220 - val_accuracy: 0.3125\n",
      "Epoch 80/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1691 - accuracy: 0.9531 - val_loss: 2.3320 - val_accuracy: 0.3125\n",
      "Epoch 81/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1691 - accuracy: 0.9531 - val_loss: 2.3420 - val_accuracy: 0.3125\n",
      "Epoch 82/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1691 - accuracy: 0.9531 - val_loss: 2.3512 - val_accuracy: 0.3125\n",
      "Epoch 83/125\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1691 - accuracy: 0.9531 - val_loss: 2.3591 - val_accuracy: 0.3125\n",
      "Epoch 84/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1691 - accuracy: 0.9531 - val_loss: 2.3654 - val_accuracy: 0.3125\n",
      "Epoch 85/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1691 - accuracy: 0.9531 - val_loss: 2.3702 - val_accuracy: 0.3125\n",
      "Epoch 86/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1691 - accuracy: 0.9531 - val_loss: 2.3737 - val_accuracy: 0.3125\n",
      "Epoch 87/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1691 - accuracy: 0.9531 - val_loss: 2.3763 - val_accuracy: 0.3125\n",
      "Epoch 88/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1691 - accuracy: 0.9531 - val_loss: 2.3782 - val_accuracy: 0.3125\n",
      "Epoch 89/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1691 - accuracy: 0.9531 - val_loss: 2.3797 - val_accuracy: 0.3125\n",
      "Epoch 90/125\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1691 - accuracy: 0.9531 - val_loss: 2.3808 - val_accuracy: 0.3125\n",
      "Epoch 91/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1691 - accuracy: 0.9531 - val_loss: 2.3815 - val_accuracy: 0.3125\n",
      "Epoch 92/125\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1691 - accuracy: 0.9531 - val_loss: 2.3817 - val_accuracy: 0.3125\n",
      "Epoch 93/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1691 - accuracy: 0.9531 - val_loss: 2.3811 - val_accuracy: 0.3125\n",
      "Epoch 94/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1691 - accuracy: 0.9531 - val_loss: 2.3799 - val_accuracy: 0.3125\n",
      "Epoch 95/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1691 - accuracy: 0.9531 - val_loss: 2.3782 - val_accuracy: 0.3125\n",
      "Epoch 96/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.3763 - val_accuracy: 0.3125\n",
      "Epoch 97/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.3745 - val_accuracy: 0.3125\n",
      "Epoch 98/125\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.3732 - val_accuracy: 0.3125\n",
      "Epoch 99/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.3727 - val_accuracy: 0.3125\n",
      "Epoch 100/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.3731 - val_accuracy: 0.3125\n",
      "Epoch 101/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.3743 - val_accuracy: 0.3125\n",
      "Epoch 102/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.3762 - val_accuracy: 0.3125\n",
      "Epoch 103/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.3785 - val_accuracy: 0.3125\n",
      "Epoch 104/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.3810 - val_accuracy: 0.3125\n",
      "Epoch 105/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.3836 - val_accuracy: 0.3125\n",
      "Epoch 106/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.3861 - val_accuracy: 0.3125\n",
      "Epoch 107/125\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.3888 - val_accuracy: 0.3125\n",
      "Epoch 108/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.3915 - val_accuracy: 0.3125\n",
      "Epoch 109/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.3944 - val_accuracy: 0.3125\n",
      "Epoch 110/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.3973 - val_accuracy: 0.3125\n",
      "Epoch 111/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.4003 - val_accuracy: 0.3125\n",
      "Epoch 112/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.4031 - val_accuracy: 0.3125\n",
      "Epoch 113/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.4056 - val_accuracy: 0.3125\n",
      "Epoch 114/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.4076 - val_accuracy: 0.3125\n",
      "Epoch 115/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.4092 - val_accuracy: 0.3125\n",
      "Epoch 116/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.4103 - val_accuracy: 0.3125\n",
      "Epoch 117/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.4111 - val_accuracy: 0.3125\n",
      "Epoch 118/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.4116 - val_accuracy: 0.3125\n",
      "Epoch 119/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.4121 - val_accuracy: 0.3125\n",
      "Epoch 120/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.4127 - val_accuracy: 0.3125\n",
      "Epoch 121/125\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.4133 - val_accuracy: 0.3125\n",
      "Epoch 122/125\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.4139 - val_accuracy: 0.3125\n",
      "Epoch 123/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.4146 - val_accuracy: 0.3125\n",
      "Epoch 124/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.4153 - val_accuracy: 0.3125\n",
      "Epoch 125/125\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 2.4160 - val_accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 11:14:16,681] Trial 0 finished with values: [2.270908832550049, 0.44999998807907104] and parameters: {'epochs': 125, 'learning_rate': 0.4105738603864939, 'units': 2, 'two_layers': False, 'batch_size': 192}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.6923 - accuracy: 0.5625 - val_loss: 1.3545 - val_accuracy: 0.5000\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4594 - accuracy: 0.5312 - val_loss: 0.9247 - val_accuracy: 0.5000\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9700 - accuracy: 0.4062 - val_loss: 0.7037 - val_accuracy: 0.5000\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4968 - accuracy: 0.7969 - val_loss: 0.7249 - val_accuracy: 0.5625\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7966 - accuracy: 0.5000 - val_loss: 0.7148 - val_accuracy: 0.6875\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6381 - accuracy: 0.7031 - val_loss: 1.0977 - val_accuracy: 0.5000\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5712 - accuracy: 0.7031 - val_loss: 0.8823 - val_accuracy: 0.6875\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5641 - accuracy: 0.7812 - val_loss: 1.1899 - val_accuracy: 0.6250\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4255 - accuracy: 0.8281 - val_loss: 1.4340 - val_accuracy: 0.4375\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4669 - accuracy: 0.8125 - val_loss: 1.8552 - val_accuracy: 0.4375\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5054 - accuracy: 0.7344 - val_loss: 0.9917 - val_accuracy: 0.6875\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4280 - accuracy: 0.7656 - val_loss: 0.7399 - val_accuracy: 0.6875\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4601 - accuracy: 0.7656 - val_loss: 1.3447 - val_accuracy: 0.6875\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4164 - accuracy: 0.8125 - val_loss: 1.8491 - val_accuracy: 0.5000\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6476 - accuracy: 0.6562 - val_loss: 1.6569 - val_accuracy: 0.3125\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5973 - accuracy: 0.7031 - val_loss: 1.2790 - val_accuracy: 0.4375\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6895 - accuracy: 0.6562 - val_loss: 0.7474 - val_accuracy: 0.6250\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6170 - accuracy: 0.7188 - val_loss: 1.5116 - val_accuracy: 0.5000\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4845 - accuracy: 0.7656 - val_loss: 1.7687 - val_accuracy: 0.4375\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5076 - accuracy: 0.7500 - val_loss: 1.8292 - val_accuracy: 0.3750\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6091 - accuracy: 0.7031 - val_loss: 1.4583 - val_accuracy: 0.3750\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6795 - accuracy: 0.6875 - val_loss: 1.7431 - val_accuracy: 0.4375\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5610 - accuracy: 0.7188 - val_loss: 1.3890 - val_accuracy: 0.4375\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5613 - accuracy: 0.8281 - val_loss: 1.4242 - val_accuracy: 0.5000\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4764 - accuracy: 0.7969 - val_loss: 1.4375 - val_accuracy: 0.5000\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5410 - accuracy: 0.7656 - val_loss: 1.4251 - val_accuracy: 0.5000\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5796 - accuracy: 0.7500 - val_loss: 1.6672 - val_accuracy: 0.3750\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5515 - accuracy: 0.7969 - val_loss: 1.4965 - val_accuracy: 0.5000\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5004 - accuracy: 0.7969 - val_loss: 1.7041 - val_accuracy: 0.4375\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5546 - accuracy: 0.7812 - val_loss: 1.7110 - val_accuracy: 0.4375\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5274 - accuracy: 0.7656 - val_loss: 1.7692 - val_accuracy: 0.4375\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4965 - accuracy: 0.7656 - val_loss: 1.4719 - val_accuracy: 0.5000\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5227 - accuracy: 0.7500 - val_loss: 1.2652 - val_accuracy: 0.6250\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5509 - accuracy: 0.7344 - val_loss: 1.2655 - val_accuracy: 0.5625\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5928 - accuracy: 0.6875 - val_loss: 1.2343 - val_accuracy: 0.5625\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5576 - accuracy: 0.7344 - val_loss: 1.1881 - val_accuracy: 0.5625\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5120 - accuracy: 0.7344 - val_loss: 1.1927 - val_accuracy: 0.5625\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5037 - accuracy: 0.7188 - val_loss: 1.2038 - val_accuracy: 0.5625\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4864 - accuracy: 0.7188 - val_loss: 1.1281 - val_accuracy: 0.6250\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4713 - accuracy: 0.7188 - val_loss: 1.2271 - val_accuracy: 0.6250\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4524 - accuracy: 0.7188 - val_loss: 1.1901 - val_accuracy: 0.6250\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4337 - accuracy: 0.7031 - val_loss: 1.0750 - val_accuracy: 0.6250\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4072 - accuracy: 0.7500 - val_loss: 1.0777 - val_accuracy: 0.5625\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3885 - accuracy: 0.7500 - val_loss: 1.1047 - val_accuracy: 0.4375\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3774 - accuracy: 0.7812 - val_loss: 1.1283 - val_accuracy: 0.4375\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3827 - accuracy: 0.7969 - val_loss: 1.1338 - val_accuracy: 0.5000\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3881 - accuracy: 0.8125 - val_loss: 1.1390 - val_accuracy: 0.4375\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3743 - accuracy: 0.7812 - val_loss: 1.0661 - val_accuracy: 0.4375\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3674 - accuracy: 0.7812 - val_loss: 1.1067 - val_accuracy: 0.6250\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3580 - accuracy: 0.7969 - val_loss: 1.1190 - val_accuracy: 0.5625\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3378 - accuracy: 0.8125 - val_loss: 1.1698 - val_accuracy: 0.6875\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3209 - accuracy: 0.8125 - val_loss: 1.3125 - val_accuracy: 0.5000\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3246 - accuracy: 0.8281 - val_loss: 1.3891 - val_accuracy: 0.5000\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3221 - accuracy: 0.8281 - val_loss: 1.5112 - val_accuracy: 0.4375\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3141 - accuracy: 0.8281 - val_loss: 1.5406 - val_accuracy: 0.4375\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3024 - accuracy: 0.8281 - val_loss: 1.5898 - val_accuracy: 0.6250\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2964 - accuracy: 0.7656 - val_loss: 1.6469 - val_accuracy: 0.5625\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3132 - accuracy: 0.7969 - val_loss: 1.7980 - val_accuracy: 0.5000\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2858 - accuracy: 0.7812 - val_loss: 1.8702 - val_accuracy: 0.4375\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2799 - accuracy: 0.8281 - val_loss: 1.8286 - val_accuracy: 0.4375\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2782 - accuracy: 0.8281 - val_loss: 1.8872 - val_accuracy: 0.4375\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2752 - accuracy: 0.8281 - val_loss: 1.9055 - val_accuracy: 0.4375\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2700 - accuracy: 0.8438 - val_loss: 1.9053 - val_accuracy: 0.5000\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2610 - accuracy: 0.8438 - val_loss: 1.8504 - val_accuracy: 0.5625\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2603 - accuracy: 0.8125 - val_loss: 1.7774 - val_accuracy: 0.5000\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2576 - accuracy: 0.8125 - val_loss: 1.6853 - val_accuracy: 0.5625\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2540 - accuracy: 0.8438 - val_loss: 1.7315 - val_accuracy: 0.5625\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2525 - accuracy: 0.8438 - val_loss: 1.7753 - val_accuracy: 0.5625\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2510 - accuracy: 0.8438 - val_loss: 1.8832 - val_accuracy: 0.5625\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2477 - accuracy: 0.8438 - val_loss: 1.8548 - val_accuracy: 0.5625\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2449 - accuracy: 0.8594 - val_loss: 1.8792 - val_accuracy: 0.5625\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2436 - accuracy: 0.8594 - val_loss: 1.9063 - val_accuracy: 0.5625\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2424 - accuracy: 0.8594 - val_loss: 1.9382 - val_accuracy: 0.5625\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2406 - accuracy: 0.8594 - val_loss: 1.9704 - val_accuracy: 0.5625\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2394 - accuracy: 0.8594 - val_loss: 2.0194 - val_accuracy: 0.5625\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2390 - accuracy: 0.8594 - val_loss: 1.8034 - val_accuracy: 0.5625\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2380 - accuracy: 0.8594 - val_loss: 1.6910 - val_accuracy: 0.5625\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2367 - accuracy: 0.8594 - val_loss: 1.6641 - val_accuracy: 0.5625\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2358 - accuracy: 0.8594 - val_loss: 1.6540 - val_accuracy: 0.5625\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2351 - accuracy: 0.8594 - val_loss: 1.6677 - val_accuracy: 0.5625\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2335 - accuracy: 0.8594 - val_loss: 1.7393 - val_accuracy: 0.5625\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2322 - accuracy: 0.8594 - val_loss: 1.9347 - val_accuracy: 0.5000\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2311 - accuracy: 0.8594 - val_loss: 2.1867 - val_accuracy: 0.5000\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2302 - accuracy: 0.8594 - val_loss: 2.3314 - val_accuracy: 0.5000\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2285 - accuracy: 0.8750 - val_loss: 2.3012 - val_accuracy: 0.5625\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2268 - accuracy: 0.8750 - val_loss: 2.5346 - val_accuracy: 0.5625\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2256 - accuracy: 0.8750 - val_loss: 2.5780 - val_accuracy: 0.5625\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2246 - accuracy: 0.8750 - val_loss: 2.5997 - val_accuracy: 0.5625\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2233 - accuracy: 0.8750 - val_loss: 2.6379 - val_accuracy: 0.5625\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2218 - accuracy: 0.8750 - val_loss: 2.6819 - val_accuracy: 0.5625\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2201 - accuracy: 0.8750 - val_loss: 2.5648 - val_accuracy: 0.5625\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2178 - accuracy: 0.8750 - val_loss: 2.6634 - val_accuracy: 0.5625\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2164 - accuracy: 0.8750 - val_loss: 2.6952 - val_accuracy: 0.5625\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2157 - accuracy: 0.8750 - val_loss: 2.7226 - val_accuracy: 0.5625\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2152 - accuracy: 0.8750 - val_loss: 2.7477 - val_accuracy: 0.5625\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2147 - accuracy: 0.8750 - val_loss: 2.7722 - val_accuracy: 0.5625\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2142 - accuracy: 0.8750 - val_loss: 2.8012 - val_accuracy: 0.5625\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2137 - accuracy: 0.8750 - val_loss: 2.8237 - val_accuracy: 0.5625\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2125 - accuracy: 0.8750 - val_loss: 2.8390 - val_accuracy: 0.5625\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2128 - accuracy: 0.8750 - val_loss: 2.8459 - val_accuracy: 0.5625\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2123 - accuracy: 0.8750 - val_loss: 2.8434 - val_accuracy: 0.5625\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2108 - accuracy: 0.8750 - val_loss: 2.8288 - val_accuracy: 0.5625\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2109 - accuracy: 0.8750 - val_loss: 2.7886 - val_accuracy: 0.5625\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2106 - accuracy: 0.8750 - val_loss: 2.7239 - val_accuracy: 0.5625\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2087 - accuracy: 0.8750 - val_loss: 2.6806 - val_accuracy: 0.5625\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2079 - accuracy: 0.8750 - val_loss: 2.6394 - val_accuracy: 0.6250\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2075 - accuracy: 0.8750 - val_loss: 2.7799 - val_accuracy: 0.6250\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2067 - accuracy: 0.8750 - val_loss: 2.4195 - val_accuracy: 0.6250\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2057 - accuracy: 0.8750 - val_loss: 2.4035 - val_accuracy: 0.6250\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2044 - accuracy: 0.8750 - val_loss: 2.4288 - val_accuracy: 0.6250\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2016 - accuracy: 0.8750 - val_loss: 2.5417 - val_accuracy: 0.7500\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1986 - accuracy: 0.8750 - val_loss: 2.7291 - val_accuracy: 0.7500\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1944 - accuracy: 0.8750 - val_loss: 2.7808 - val_accuracy: 0.7500\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2177 - accuracy: 0.8750 - val_loss: 2.6985 - val_accuracy: 0.7500\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2045 - accuracy: 0.8906 - val_loss: 2.4198 - val_accuracy: 0.6875\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2082 - accuracy: 0.8438 - val_loss: 2.4378 - val_accuracy: 0.7500\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1795 - accuracy: 0.9062 - val_loss: 2.5966 - val_accuracy: 0.7500\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2204 - accuracy: 0.8906 - val_loss: 2.8516 - val_accuracy: 0.7500\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2250 - accuracy: 0.8594 - val_loss: 2.9624 - val_accuracy: 0.5625\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2108 - accuracy: 0.8750 - val_loss: 3.0160 - val_accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 11:14:19,498] Trial 1 finished with values: [3.6054584980010986, 0.4000000059604645] and parameters: {'epochs': 120, 'learning_rate': 0.4628833401454628, 'units': 10, 'two_layers': False, 'batch_size': 131}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/111\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6986 - accuracy: 0.3594 - val_loss: 1.0115 - val_accuracy: 0.5000\n",
      "Epoch 2/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8575 - accuracy: 0.5000 - val_loss: 0.8467 - val_accuracy: 0.5000\n",
      "Epoch 3/111\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6865 - accuracy: 0.5781 - val_loss: 1.1729 - val_accuracy: 0.5625\n",
      "Epoch 4/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7289 - accuracy: 0.6562 - val_loss: 0.9381 - val_accuracy: 0.5000\n",
      "Epoch 5/111\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3537 - accuracy: 0.8750 - val_loss: 0.9180 - val_accuracy: 0.5000\n",
      "Epoch 6/111\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3261 - accuracy: 0.8750 - val_loss: 1.2218 - val_accuracy: 0.3750\n",
      "Epoch 7/111\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4161 - accuracy: 0.8750 - val_loss: 1.3056 - val_accuracy: 0.5000\n",
      "Epoch 8/111\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2127 - accuracy: 0.9531 - val_loss: 1.8362 - val_accuracy: 0.3750\n",
      "Epoch 9/111\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3150 - accuracy: 0.9062 - val_loss: 2.0418 - val_accuracy: 0.3750\n",
      "Epoch 10/111\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3698 - accuracy: 0.8750 - val_loss: 1.2175 - val_accuracy: 0.5625\n",
      "Epoch 11/111\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4739 - accuracy: 0.8594 - val_loss: 1.0321 - val_accuracy: 0.5000\n",
      "Epoch 12/111\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4108 - accuracy: 0.8750 - val_loss: 1.1080 - val_accuracy: 0.3750\n",
      "Epoch 13/111\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4102 - accuracy: 0.8594 - val_loss: 0.9747 - val_accuracy: 0.3750\n",
      "Epoch 14/111\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3428 - accuracy: 0.9375 - val_loss: 1.0333 - val_accuracy: 0.3750\n",
      "Epoch 15/111\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3656 - accuracy: 0.9062 - val_loss: 0.9302 - val_accuracy: 0.5625\n",
      "Epoch 16/111\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3692 - accuracy: 0.8750 - val_loss: 1.1247 - val_accuracy: 0.5000\n",
      "Epoch 17/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3469 - accuracy: 0.9062 - val_loss: 1.4555 - val_accuracy: 0.5000\n",
      "Epoch 18/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2420 - accuracy: 0.9375 - val_loss: 1.5385 - val_accuracy: 0.4375\n",
      "Epoch 19/111\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2484 - accuracy: 0.9375 - val_loss: 1.9501 - val_accuracy: 0.3750\n",
      "Epoch 20/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2593 - accuracy: 0.9375 - val_loss: 2.1025 - val_accuracy: 0.3125\n",
      "Epoch 21/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2664 - accuracy: 0.9375 - val_loss: 2.0779 - val_accuracy: 0.3125\n",
      "Epoch 22/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2629 - accuracy: 0.9375 - val_loss: 2.1017 - val_accuracy: 0.3125\n",
      "Epoch 23/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2606 - accuracy: 0.9219 - val_loss: 1.8755 - val_accuracy: 0.3125\n",
      "Epoch 24/111\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2426 - accuracy: 0.9219 - val_loss: 1.6411 - val_accuracy: 0.3750\n",
      "Epoch 25/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2279 - accuracy: 0.9375 - val_loss: 1.4796 - val_accuracy: 0.3750\n",
      "Epoch 26/111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2663 - accuracy: 0.9219 - val_loss: 1.2159 - val_accuracy: 0.4375\n",
      "Epoch 27/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2581 - accuracy: 0.9219 - val_loss: 1.1848 - val_accuracy: 0.3750\n",
      "Epoch 28/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2896 - accuracy: 0.9219 - val_loss: 1.2240 - val_accuracy: 0.3750\n",
      "Epoch 29/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2614 - accuracy: 0.9219 - val_loss: 1.5600 - val_accuracy: 0.3750\n",
      "Epoch 30/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5576 - accuracy: 0.7656 - val_loss: 1.1115 - val_accuracy: 0.3750\n",
      "Epoch 31/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2676 - accuracy: 0.9062 - val_loss: 1.5216 - val_accuracy: 0.5000\n",
      "Epoch 32/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3232 - accuracy: 0.8906 - val_loss: 1.3933 - val_accuracy: 0.4375\n",
      "Epoch 33/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3254 - accuracy: 0.9062 - val_loss: 1.1835 - val_accuracy: 0.4375\n",
      "Epoch 34/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2440 - accuracy: 0.9219 - val_loss: 1.4097 - val_accuracy: 0.5625\n",
      "Epoch 35/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2918 - accuracy: 0.8906 - val_loss: 1.2391 - val_accuracy: 0.5625\n",
      "Epoch 36/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2419 - accuracy: 0.9062 - val_loss: 1.3105 - val_accuracy: 0.5625\n",
      "Epoch 37/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2738 - accuracy: 0.9219 - val_loss: 1.7508 - val_accuracy: 0.5000\n",
      "Epoch 38/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2808 - accuracy: 0.8438 - val_loss: 1.8287 - val_accuracy: 0.4375\n",
      "Epoch 39/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2742 - accuracy: 0.8594 - val_loss: 1.8640 - val_accuracy: 0.3750\n",
      "Epoch 40/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3360 - accuracy: 0.8750 - val_loss: 1.7453 - val_accuracy: 0.4375\n",
      "Epoch 41/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3125 - accuracy: 0.8906 - val_loss: 1.5574 - val_accuracy: 0.4375\n",
      "Epoch 42/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2482 - accuracy: 0.8906 - val_loss: 1.4797 - val_accuracy: 0.4375\n",
      "Epoch 43/111\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2314 - accuracy: 0.9219 - val_loss: 1.4477 - val_accuracy: 0.4375\n",
      "Epoch 44/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1433 - accuracy: 0.9688 - val_loss: 1.2224 - val_accuracy: 0.5000\n",
      "Epoch 45/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2202 - accuracy: 0.9219 - val_loss: 1.5017 - val_accuracy: 0.4375\n",
      "Epoch 46/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2377 - accuracy: 0.9062 - val_loss: 1.6850 - val_accuracy: 0.4375\n",
      "Epoch 47/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2839 - accuracy: 0.8594 - val_loss: 1.4936 - val_accuracy: 0.5000\n",
      "Epoch 48/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2925 - accuracy: 0.8594 - val_loss: 1.5490 - val_accuracy: 0.5000\n",
      "Epoch 49/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3198 - accuracy: 0.8594 - val_loss: 1.4236 - val_accuracy: 0.5000\n",
      "Epoch 50/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2504 - accuracy: 0.9219 - val_loss: 1.4095 - val_accuracy: 0.6250\n",
      "Epoch 51/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3184 - accuracy: 0.9062 - val_loss: 1.5354 - val_accuracy: 0.5000\n",
      "Epoch 52/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3562 - accuracy: 0.8906 - val_loss: 1.5659 - val_accuracy: 0.6250\n",
      "Epoch 53/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3475 - accuracy: 0.8750 - val_loss: 1.6683 - val_accuracy: 0.6250\n",
      "Epoch 54/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2683 - accuracy: 0.9219 - val_loss: 1.8042 - val_accuracy: 0.4375\n",
      "Epoch 55/111\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2703 - accuracy: 0.9062 - val_loss: 1.7196 - val_accuracy: 0.4375\n",
      "Epoch 56/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3040 - accuracy: 0.8906 - val_loss: 1.4694 - val_accuracy: 0.5625\n",
      "Epoch 57/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2925 - accuracy: 0.9219 - val_loss: 1.7342 - val_accuracy: 0.5625\n",
      "Epoch 58/111\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3794 - accuracy: 0.8750 - val_loss: 1.1947 - val_accuracy: 0.5625\n",
      "Epoch 59/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3487 - accuracy: 0.8594 - val_loss: 1.1482 - val_accuracy: 0.6250\n",
      "Epoch 60/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3251 - accuracy: 0.8594 - val_loss: 1.4334 - val_accuracy: 0.5000\n",
      "Epoch 61/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3363 - accuracy: 0.8750 - val_loss: 1.6431 - val_accuracy: 0.3750\n",
      "Epoch 62/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4773 - accuracy: 0.8125 - val_loss: 1.6182 - val_accuracy: 0.5000\n",
      "Epoch 63/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4190 - accuracy: 0.8594 - val_loss: 1.7812 - val_accuracy: 0.4375\n",
      "Epoch 64/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3238 - accuracy: 0.8906 - val_loss: 1.8824 - val_accuracy: 0.3750\n",
      "Epoch 65/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5067 - accuracy: 0.8125 - val_loss: 1.9440 - val_accuracy: 0.3750\n",
      "Epoch 66/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3712 - accuracy: 0.8594 - val_loss: 1.8550 - val_accuracy: 0.3750\n",
      "Epoch 67/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4027 - accuracy: 0.8438 - val_loss: 1.8872 - val_accuracy: 0.3750\n",
      "Epoch 68/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4096 - accuracy: 0.8594 - val_loss: 1.8555 - val_accuracy: 0.3750\n",
      "Epoch 69/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3649 - accuracy: 0.8906 - val_loss: 1.4024 - val_accuracy: 0.4375\n",
      "Epoch 70/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4137 - accuracy: 0.8438 - val_loss: 1.4089 - val_accuracy: 0.3750\n",
      "Epoch 71/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4896 - accuracy: 0.8281 - val_loss: 1.4834 - val_accuracy: 0.3125\n",
      "Epoch 72/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4485 - accuracy: 0.8281 - val_loss: 1.0479 - val_accuracy: 0.5000\n",
      "Epoch 73/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4167 - accuracy: 0.8281 - val_loss: 0.9026 - val_accuracy: 0.5000\n",
      "Epoch 74/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4740 - accuracy: 0.7969 - val_loss: 0.7858 - val_accuracy: 0.4375\n",
      "Epoch 75/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4615 - accuracy: 0.7188 - val_loss: 1.1220 - val_accuracy: 0.6875\n",
      "Epoch 76/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4387 - accuracy: 0.7656 - val_loss: 0.7739 - val_accuracy: 0.6250\n",
      "Epoch 77/111\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5189 - accuracy: 0.7500 - val_loss: 0.9592 - val_accuracy: 0.5000\n",
      "Epoch 78/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4939 - accuracy: 0.7500 - val_loss: 1.1135 - val_accuracy: 0.5625\n",
      "Epoch 79/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4984 - accuracy: 0.8125 - val_loss: 1.1994 - val_accuracy: 0.3125\n",
      "Epoch 80/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5315 - accuracy: 0.7656 - val_loss: 1.0728 - val_accuracy: 0.4375\n",
      "Epoch 81/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6242 - accuracy: 0.7344 - val_loss: 0.7929 - val_accuracy: 0.6875\n",
      "Epoch 82/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5264 - accuracy: 0.7500 - val_loss: 0.7746 - val_accuracy: 0.5625\n",
      "Epoch 83/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4925 - accuracy: 0.7656 - val_loss: 0.8823 - val_accuracy: 0.4375\n",
      "Epoch 84/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4470 - accuracy: 0.7969 - val_loss: 0.9997 - val_accuracy: 0.4375\n",
      "Epoch 85/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5206 - accuracy: 0.7500 - val_loss: 0.9449 - val_accuracy: 0.5625\n",
      "Epoch 86/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7595 - accuracy: 0.5469 - val_loss: 1.2109 - val_accuracy: 0.3750\n",
      "Epoch 87/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6855 - accuracy: 0.6562 - val_loss: 1.0726 - val_accuracy: 0.3750\n",
      "Epoch 88/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6586 - accuracy: 0.6406 - val_loss: 1.0829 - val_accuracy: 0.3750\n",
      "Epoch 89/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6707 - accuracy: 0.6250 - val_loss: 1.0946 - val_accuracy: 0.4375\n",
      "Epoch 90/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6758 - accuracy: 0.6094 - val_loss: 1.2453 - val_accuracy: 0.4375\n",
      "Epoch 91/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6089 - accuracy: 0.6562 - val_loss: 2.0281 - val_accuracy: 0.2500\n",
      "Epoch 92/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5699 - accuracy: 0.7812 - val_loss: 2.3850 - val_accuracy: 0.3125\n",
      "Epoch 93/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5059 - accuracy: 0.7812 - val_loss: 2.6657 - val_accuracy: 0.3125\n",
      "Epoch 94/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7952 - accuracy: 0.7031 - val_loss: 2.8703 - val_accuracy: 0.1875\n",
      "Epoch 95/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5073 - accuracy: 0.7812 - val_loss: 2.7081 - val_accuracy: 0.1875\n",
      "Epoch 96/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6406 - accuracy: 0.7344 - val_loss: 2.3080 - val_accuracy: 0.1250\n",
      "Epoch 97/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7021 - accuracy: 0.6875 - val_loss: 2.1322 - val_accuracy: 0.2500\n",
      "Epoch 98/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6959 - accuracy: 0.7344 - val_loss: 1.7029 - val_accuracy: 0.3125\n",
      "Epoch 99/111\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5937 - accuracy: 0.7500 - val_loss: 1.6182 - val_accuracy: 0.3125\n",
      "Epoch 100/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5864 - accuracy: 0.7500 - val_loss: 1.4328 - val_accuracy: 0.3750\n",
      "Epoch 101/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6358 - accuracy: 0.7031 - val_loss: 1.3910 - val_accuracy: 0.3125\n",
      "Epoch 102/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6314 - accuracy: 0.7031 - val_loss: 1.2591 - val_accuracy: 0.3750\n",
      "Epoch 103/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5521 - accuracy: 0.7188 - val_loss: 1.2663 - val_accuracy: 0.1875\n",
      "Epoch 104/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5308 - accuracy: 0.7500 - val_loss: 1.1529 - val_accuracy: 0.5000\n",
      "Epoch 105/111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5928 - accuracy: 0.6719 - val_loss: 1.2077 - val_accuracy: 0.5000\n",
      "Epoch 106/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6998 - accuracy: 0.6562 - val_loss: 1.2892 - val_accuracy: 0.5000\n",
      "Epoch 107/111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6102 - accuracy: 0.6719 - val_loss: 1.1583 - val_accuracy: 0.5000\n",
      "Epoch 108/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5439 - accuracy: 0.6719 - val_loss: 1.2371 - val_accuracy: 0.4375\n",
      "Epoch 109/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5241 - accuracy: 0.7656 - val_loss: 1.2902 - val_accuracy: 0.5625\n",
      "Epoch 110/111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6219 - accuracy: 0.6875 - val_loss: 0.8639 - val_accuracy: 0.6875\n",
      "Epoch 111/111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5435 - accuracy: 0.7656 - val_loss: 0.9724 - val_accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 11:14:22,783] Trial 2 finished with values: [1.2428960800170898, 0.3499999940395355] and parameters: {'epochs': 111, 'learning_rate': 0.3594445669313056, 'units': 10, 'two_layers': True, 'batch_size': 242}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/132\n",
      "1/1 [==============================] - 1s 892ms/step - loss: 0.6871 - accuracy: 0.6094 - val_loss: 1.3381 - val_accuracy: 0.5625\n",
      "Epoch 2/132\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5743 - accuracy: 0.8125 - val_loss: 1.3717 - val_accuracy: 0.5000\n",
      "Epoch 3/132\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.9447 - accuracy: 0.6250 - val_loss: 0.9280 - val_accuracy: 0.4375\n",
      "Epoch 4/132\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4051 - accuracy: 0.8906 - val_loss: 0.9097 - val_accuracy: 0.3750\n",
      "Epoch 5/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4790 - accuracy: 0.8281 - val_loss: 0.9474 - val_accuracy: 0.3125\n",
      "Epoch 6/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4724 - accuracy: 0.8750 - val_loss: 0.9087 - val_accuracy: 0.4375\n",
      "Epoch 7/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4266 - accuracy: 0.8750 - val_loss: 0.9040 - val_accuracy: 0.3750\n",
      "Epoch 8/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3653 - accuracy: 0.8906 - val_loss: 1.1079 - val_accuracy: 0.5000\n",
      "Epoch 9/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3189 - accuracy: 0.9062 - val_loss: 1.3010 - val_accuracy: 0.4375\n",
      "Epoch 10/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2874 - accuracy: 0.9219 - val_loss: 1.3855 - val_accuracy: 0.5000\n",
      "Epoch 11/132\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2999 - accuracy: 0.9219 - val_loss: 1.2886 - val_accuracy: 0.5625\n",
      "Epoch 12/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3256 - accuracy: 0.9219 - val_loss: 1.3507 - val_accuracy: 0.5625\n",
      "Epoch 13/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3172 - accuracy: 0.9375 - val_loss: 1.4984 - val_accuracy: 0.5625\n",
      "Epoch 14/132\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2871 - accuracy: 0.9375 - val_loss: 2.0172 - val_accuracy: 0.3750\n",
      "Epoch 15/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3979 - accuracy: 0.8906 - val_loss: 1.8460 - val_accuracy: 0.5000\n",
      "Epoch 16/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3515 - accuracy: 0.9219 - val_loss: 1.9002 - val_accuracy: 0.5000\n",
      "Epoch 17/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4049 - accuracy: 0.9062 - val_loss: 1.5426 - val_accuracy: 0.5000\n",
      "Epoch 18/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6615 - accuracy: 0.8438 - val_loss: 1.4255 - val_accuracy: 0.5000\n",
      "Epoch 19/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6366 - accuracy: 0.7812 - val_loss: 1.2351 - val_accuracy: 0.5000\n",
      "Epoch 20/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5759 - accuracy: 0.7500 - val_loss: 1.0739 - val_accuracy: 0.5000\n",
      "Epoch 21/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5865 - accuracy: 0.7188 - val_loss: 0.9348 - val_accuracy: 0.5000\n",
      "Epoch 22/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5902 - accuracy: 0.7188 - val_loss: 0.9958 - val_accuracy: 0.4375\n",
      "Epoch 23/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5020 - accuracy: 0.7969 - val_loss: 0.8815 - val_accuracy: 0.5000\n",
      "Epoch 24/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4606 - accuracy: 0.8125 - val_loss: 1.0679 - val_accuracy: 0.4375\n",
      "Epoch 25/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4377 - accuracy: 0.8281 - val_loss: 1.4250 - val_accuracy: 0.4375\n",
      "Epoch 26/132\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5227 - accuracy: 0.6875 - val_loss: 1.3649 - val_accuracy: 0.5000\n",
      "Epoch 27/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5049 - accuracy: 0.8281 - val_loss: 1.2873 - val_accuracy: 0.5000\n",
      "Epoch 28/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4766 - accuracy: 0.8281 - val_loss: 1.2093 - val_accuracy: 0.5000\n",
      "Epoch 29/132\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4354 - accuracy: 0.8281 - val_loss: 1.2786 - val_accuracy: 0.4375\n",
      "Epoch 30/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3823 - accuracy: 0.8594 - val_loss: 1.0132 - val_accuracy: 0.5625\n",
      "Epoch 31/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3650 - accuracy: 0.8594 - val_loss: 0.9708 - val_accuracy: 0.5625\n",
      "Epoch 32/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3662 - accuracy: 0.8594 - val_loss: 0.9497 - val_accuracy: 0.5625\n",
      "Epoch 33/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3791 - accuracy: 0.8594 - val_loss: 0.9468 - val_accuracy: 0.5625\n",
      "Epoch 34/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3890 - accuracy: 0.8594 - val_loss: 0.9558 - val_accuracy: 0.5625\n",
      "Epoch 35/132\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3982 - accuracy: 0.8594 - val_loss: 0.9711 - val_accuracy: 0.5625\n",
      "Epoch 36/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3984 - accuracy: 0.8594 - val_loss: 0.9906 - val_accuracy: 0.5000\n",
      "Epoch 37/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3892 - accuracy: 0.8750 - val_loss: 1.0153 - val_accuracy: 0.5000\n",
      "Epoch 38/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3462 - accuracy: 0.8906 - val_loss: 1.0490 - val_accuracy: 0.5000\n",
      "Epoch 39/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3295 - accuracy: 0.8906 - val_loss: 1.0928 - val_accuracy: 0.5000\n",
      "Epoch 40/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3164 - accuracy: 0.8906 - val_loss: 1.1446 - val_accuracy: 0.5000\n",
      "Epoch 41/132\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3092 - accuracy: 0.8906 - val_loss: 1.2006 - val_accuracy: 0.5000\n",
      "Epoch 42/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3076 - accuracy: 0.8906 - val_loss: 1.2570 - val_accuracy: 0.5000\n",
      "Epoch 43/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3101 - accuracy: 0.8906 - val_loss: 1.3108 - val_accuracy: 0.5000\n",
      "Epoch 44/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3148 - accuracy: 0.8906 - val_loss: 1.3609 - val_accuracy: 0.5000\n",
      "Epoch 45/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3196 - accuracy: 0.8906 - val_loss: 1.4071 - val_accuracy: 0.5000\n",
      "Epoch 46/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3227 - accuracy: 0.8906 - val_loss: 1.4498 - val_accuracy: 0.5000\n",
      "Epoch 47/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3234 - accuracy: 0.8906 - val_loss: 1.4874 - val_accuracy: 0.5000\n",
      "Epoch 48/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3216 - accuracy: 0.8906 - val_loss: 1.5162 - val_accuracy: 0.5000\n",
      "Epoch 49/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3182 - accuracy: 0.8906 - val_loss: 1.5330 - val_accuracy: 0.5000\n",
      "Epoch 50/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2918 - accuracy: 0.9062 - val_loss: 1.5390 - val_accuracy: 0.5000\n",
      "Epoch 51/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2863 - accuracy: 0.9062 - val_loss: 1.5362 - val_accuracy: 0.5000\n",
      "Epoch 52/132\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2819 - accuracy: 0.9062 - val_loss: 1.5276 - val_accuracy: 0.5000\n",
      "Epoch 53/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2794 - accuracy: 0.9062 - val_loss: 1.5161 - val_accuracy: 0.5000\n",
      "Epoch 54/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2788 - accuracy: 0.9062 - val_loss: 1.5045 - val_accuracy: 0.5000\n",
      "Epoch 55/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2799 - accuracy: 0.9062 - val_loss: 1.4945 - val_accuracy: 0.5000\n",
      "Epoch 56/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2820 - accuracy: 0.9062 - val_loss: 1.4875 - val_accuracy: 0.5000\n",
      "Epoch 57/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2840 - accuracy: 0.9062 - val_loss: 1.4842 - val_accuracy: 0.5000\n",
      "Epoch 58/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2852 - accuracy: 0.9062 - val_loss: 1.4849 - val_accuracy: 0.5000\n",
      "Epoch 59/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2852 - accuracy: 0.9062 - val_loss: 1.4896 - val_accuracy: 0.5000\n",
      "Epoch 60/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2839 - accuracy: 0.9062 - val_loss: 1.4980 - val_accuracy: 0.5000\n",
      "Epoch 61/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2820 - accuracy: 0.9062 - val_loss: 1.5096 - val_accuracy: 0.5000\n",
      "Epoch 62/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2800 - accuracy: 0.9062 - val_loss: 1.5233 - val_accuracy: 0.5000\n",
      "Epoch 63/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2784 - accuracy: 0.9062 - val_loss: 1.5382 - val_accuracy: 0.5000\n",
      "Epoch 64/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2778 - accuracy: 0.9062 - val_loss: 1.5528 - val_accuracy: 0.5000\n",
      "Epoch 65/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2779 - accuracy: 0.9062 - val_loss: 1.5659 - val_accuracy: 0.5000\n",
      "Epoch 66/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2786 - accuracy: 0.9062 - val_loss: 1.5764 - val_accuracy: 0.5000\n",
      "Epoch 67/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2794 - accuracy: 0.9062 - val_loss: 1.5837 - val_accuracy: 0.5000\n",
      "Epoch 68/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2800 - accuracy: 0.9062 - val_loss: 1.5874 - val_accuracy: 0.5000\n",
      "Epoch 69/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2802 - accuracy: 0.9062 - val_loss: 1.5878 - val_accuracy: 0.5000\n",
      "Epoch 70/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2798 - accuracy: 0.9062 - val_loss: 1.5853 - val_accuracy: 0.5000\n",
      "Epoch 71/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2792 - accuracy: 0.9062 - val_loss: 1.5808 - val_accuracy: 0.5000\n",
      "Epoch 72/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2784 - accuracy: 0.9062 - val_loss: 1.5753 - val_accuracy: 0.5000\n",
      "Epoch 73/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2778 - accuracy: 0.9062 - val_loss: 1.5697 - val_accuracy: 0.5000\n",
      "Epoch 74/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2775 - accuracy: 0.9062 - val_loss: 1.5647 - val_accuracy: 0.5000\n",
      "Epoch 75/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2775 - accuracy: 0.9062 - val_loss: 1.5610 - val_accuracy: 0.5000\n",
      "Epoch 76/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2777 - accuracy: 0.9062 - val_loss: 1.5591 - val_accuracy: 0.5000\n",
      "Epoch 77/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2781 - accuracy: 0.9062 - val_loss: 1.5592 - val_accuracy: 0.5000\n",
      "Epoch 78/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2783 - accuracy: 0.9062 - val_loss: 1.5612 - val_accuracy: 0.5000\n",
      "Epoch 79/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2783 - accuracy: 0.9062 - val_loss: 1.5650 - val_accuracy: 0.5000\n",
      "Epoch 80/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2782 - accuracy: 0.9062 - val_loss: 1.5703 - val_accuracy: 0.5000\n",
      "Epoch 81/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2779 - accuracy: 0.9062 - val_loss: 1.5766 - val_accuracy: 0.5000\n",
      "Epoch 82/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2776 - accuracy: 0.9062 - val_loss: 1.5835 - val_accuracy: 0.5000\n",
      "Epoch 83/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2774 - accuracy: 0.9062 - val_loss: 1.5903 - val_accuracy: 0.5000\n",
      "Epoch 84/132\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2773 - accuracy: 0.9062 - val_loss: 1.5965 - val_accuracy: 0.5000\n",
      "Epoch 85/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2773 - accuracy: 0.9062 - val_loss: 1.6016 - val_accuracy: 0.5000\n",
      "Epoch 86/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2774 - accuracy: 0.9062 - val_loss: 1.6052 - val_accuracy: 0.5000\n",
      "Epoch 87/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2775 - accuracy: 0.9062 - val_loss: 1.6074 - val_accuracy: 0.5000\n",
      "Epoch 88/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2776 - accuracy: 0.9062 - val_loss: 1.6080 - val_accuracy: 0.5000\n",
      "Epoch 89/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2775 - accuracy: 0.9062 - val_loss: 1.6072 - val_accuracy: 0.5000\n",
      "Epoch 90/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2775 - accuracy: 0.9062 - val_loss: 1.6056 - val_accuracy: 0.5000\n",
      "Epoch 91/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2773 - accuracy: 0.9062 - val_loss: 1.6033 - val_accuracy: 0.5000\n",
      "Epoch 92/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2772 - accuracy: 0.9062 - val_loss: 1.6010 - val_accuracy: 0.5000\n",
      "Epoch 93/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2772 - accuracy: 0.9062 - val_loss: 1.5990 - val_accuracy: 0.5000\n",
      "Epoch 94/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2771 - accuracy: 0.9062 - val_loss: 1.5976 - val_accuracy: 0.5000\n",
      "Epoch 95/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2772 - accuracy: 0.9062 - val_loss: 1.5972 - val_accuracy: 0.5000\n",
      "Epoch 96/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2772 - accuracy: 0.9062 - val_loss: 1.5979 - val_accuracy: 0.5000\n",
      "Epoch 97/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2772 - accuracy: 0.9062 - val_loss: 1.5996 - val_accuracy: 0.5000\n",
      "Epoch 98/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2772 - accuracy: 0.9062 - val_loss: 1.6022 - val_accuracy: 0.5000\n",
      "Epoch 99/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2772 - accuracy: 0.9062 - val_loss: 1.6056 - val_accuracy: 0.5000\n",
      "Epoch 100/132\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2771 - accuracy: 0.9062 - val_loss: 1.6095 - val_accuracy: 0.5000\n",
      "Epoch 101/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2771 - accuracy: 0.9062 - val_loss: 1.6136 - val_accuracy: 0.5000\n",
      "Epoch 102/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2770 - accuracy: 0.9062 - val_loss: 1.6176 - val_accuracy: 0.5000\n",
      "Epoch 103/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2770 - accuracy: 0.9062 - val_loss: 1.6211 - val_accuracy: 0.5000\n",
      "Epoch 104/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2770 - accuracy: 0.9062 - val_loss: 1.6241 - val_accuracy: 0.5000\n",
      "Epoch 105/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2770 - accuracy: 0.9062 - val_loss: 1.6263 - val_accuracy: 0.5000\n",
      "Epoch 106/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2770 - accuracy: 0.9062 - val_loss: 1.6278 - val_accuracy: 0.5000\n",
      "Epoch 107/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2770 - accuracy: 0.9062 - val_loss: 1.6286 - val_accuracy: 0.5000\n",
      "Epoch 108/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2769 - accuracy: 0.9062 - val_loss: 1.6287 - val_accuracy: 0.5000\n",
      "Epoch 109/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2769 - accuracy: 0.9062 - val_loss: 1.6285 - val_accuracy: 0.5000\n",
      "Epoch 110/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2769 - accuracy: 0.9062 - val_loss: 1.6281 - val_accuracy: 0.5000\n",
      "Epoch 111/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2768 - accuracy: 0.9062 - val_loss: 1.6278 - val_accuracy: 0.5000\n",
      "Epoch 112/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2768 - accuracy: 0.9062 - val_loss: 1.6276 - val_accuracy: 0.5000\n",
      "Epoch 113/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2768 - accuracy: 0.9062 - val_loss: 1.6279 - val_accuracy: 0.5000\n",
      "Epoch 114/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2767 - accuracy: 0.9062 - val_loss: 1.6286 - val_accuracy: 0.5000\n",
      "Epoch 115/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2767 - accuracy: 0.9062 - val_loss: 1.6299 - val_accuracy: 0.5000\n",
      "Epoch 116/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2767 - accuracy: 0.9062 - val_loss: 1.6316 - val_accuracy: 0.5000\n",
      "Epoch 117/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2766 - accuracy: 0.9062 - val_loss: 1.6337 - val_accuracy: 0.5000\n",
      "Epoch 118/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2766 - accuracy: 0.9062 - val_loss: 1.6360 - val_accuracy: 0.5000\n",
      "Epoch 119/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2765 - accuracy: 0.9062 - val_loss: 1.6386 - val_accuracy: 0.5000\n",
      "Epoch 120/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2765 - accuracy: 0.9062 - val_loss: 1.6411 - val_accuracy: 0.5000\n",
      "Epoch 121/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2764 - accuracy: 0.9062 - val_loss: 1.6435 - val_accuracy: 0.5000\n",
      "Epoch 122/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2763 - accuracy: 0.9062 - val_loss: 1.6457 - val_accuracy: 0.5000\n",
      "Epoch 123/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2762 - accuracy: 0.9062 - val_loss: 1.6476 - val_accuracy: 0.5000\n",
      "Epoch 124/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2762 - accuracy: 0.9062 - val_loss: 1.6493 - val_accuracy: 0.5000\n",
      "Epoch 125/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2761 - accuracy: 0.9062 - val_loss: 1.6508 - val_accuracy: 0.5000\n",
      "Epoch 126/132\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2759 - accuracy: 0.9062 - val_loss: 1.6521 - val_accuracy: 0.5000\n",
      "Epoch 127/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2758 - accuracy: 0.9062 - val_loss: 1.6533 - val_accuracy: 0.5000\n",
      "Epoch 128/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2756 - accuracy: 0.9062 - val_loss: 1.6546 - val_accuracy: 0.5000\n",
      "Epoch 129/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2754 - accuracy: 0.9062 - val_loss: 1.6560 - val_accuracy: 0.5000\n",
      "Epoch 130/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2752 - accuracy: 0.9062 - val_loss: 1.6577 - val_accuracy: 0.5000\n",
      "Epoch 131/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2748 - accuracy: 0.9062 - val_loss: 1.6597 - val_accuracy: 0.5000\n",
      "Epoch 132/132\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2744 - accuracy: 0.9062 - val_loss: 1.6620 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 11:14:26,192] Trial 3 finished with values: [1.5847666263580322, 0.44999998807907104] and parameters: {'epochs': 132, 'learning_rate': 0.4495750064714586, 'units': 2, 'two_layers': True, 'batch_size': 109}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/155\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.6824 - accuracy: 0.5781 - val_loss: 0.6804 - val_accuracy: 0.6250\n",
      "Epoch 2/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5193 - accuracy: 0.8750 - val_loss: 0.6053 - val_accuracy: 0.7500\n",
      "Epoch 3/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4026 - accuracy: 0.9531 - val_loss: 0.6068 - val_accuracy: 0.7500\n",
      "Epoch 4/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3309 - accuracy: 0.9688 - val_loss: 0.6588 - val_accuracy: 0.6875\n",
      "Epoch 5/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2779 - accuracy: 0.9688 - val_loss: 0.7020 - val_accuracy: 0.5625\n",
      "Epoch 6/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2287 - accuracy: 0.9688 - val_loss: 0.8268 - val_accuracy: 0.5000\n",
      "Epoch 7/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1923 - accuracy: 0.9844 - val_loss: 0.8960 - val_accuracy: 0.4375\n",
      "Epoch 8/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1528 - accuracy: 0.9844 - val_loss: 0.9831 - val_accuracy: 0.4375\n",
      "Epoch 9/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1259 - accuracy: 1.0000 - val_loss: 1.0839 - val_accuracy: 0.4375\n",
      "Epoch 10/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1060 - accuracy: 0.9844 - val_loss: 0.9770 - val_accuracy: 0.6250\n",
      "Epoch 11/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0723 - accuracy: 1.0000 - val_loss: 0.9041 - val_accuracy: 0.6875\n",
      "Epoch 12/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0757 - accuracy: 1.0000 - val_loss: 0.8504 - val_accuracy: 0.7500\n",
      "Epoch 13/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0663 - accuracy: 0.9844 - val_loss: 0.8295 - val_accuracy: 0.7500\n",
      "Epoch 14/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.7349 - val_accuracy: 0.7500\n",
      "Epoch 15/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.7566 - val_accuracy: 0.6875\n",
      "Epoch 16/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0563 - accuracy: 0.9844 - val_loss: 0.9045 - val_accuracy: 0.6875\n",
      "Epoch 17/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 1.0168 - val_accuracy: 0.6875\n",
      "Epoch 18/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 1.1559 - val_accuracy: 0.6875\n",
      "Epoch 19/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0606 - accuracy: 0.9844 - val_loss: 1.0340 - val_accuracy: 0.6875\n",
      "Epoch 20/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.8711 - val_accuracy: 0.6875\n",
      "Epoch 21/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.9660 - val_accuracy: 0.6875\n",
      "Epoch 22/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.0438 - val_accuracy: 0.6875\n",
      "Epoch 23/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.9710 - val_accuracy: 0.6875\n",
      "Epoch 24/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.9482 - val_accuracy: 0.6875\n",
      "Epoch 25/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.9432 - val_accuracy: 0.7500\n",
      "Epoch 26/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.9430 - val_accuracy: 0.7500\n",
      "Epoch 27/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.9475 - val_accuracy: 0.7500\n",
      "Epoch 28/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.9557 - val_accuracy: 0.7500\n",
      "Epoch 29/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.9663 - val_accuracy: 0.7500\n",
      "Epoch 30/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.9788 - val_accuracy: 0.7500\n",
      "Epoch 31/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.9925 - val_accuracy: 0.7500\n",
      "Epoch 32/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0063 - val_accuracy: 0.7500\n",
      "Epoch 33/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0194 - val_accuracy: 0.7500\n",
      "Epoch 34/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.0315 - val_accuracy: 0.7500\n",
      "Epoch 35/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.0426 - val_accuracy: 0.7500\n",
      "Epoch 36/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.0528 - val_accuracy: 0.7500\n",
      "Epoch 37/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.0624 - val_accuracy: 0.7500\n",
      "Epoch 38/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.0714 - val_accuracy: 0.7500\n",
      "Epoch 39/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.0799 - val_accuracy: 0.7500\n",
      "Epoch 40/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.0880 - val_accuracy: 0.7500\n",
      "Epoch 41/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.0955 - val_accuracy: 0.7500\n",
      "Epoch 42/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1026 - val_accuracy: 0.7500\n",
      "Epoch 43/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1094 - val_accuracy: 0.7500\n",
      "Epoch 44/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1158 - val_accuracy: 0.7500\n",
      "Epoch 45/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.1219 - val_accuracy: 0.7500\n",
      "Epoch 46/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1276 - val_accuracy: 0.7500\n",
      "Epoch 47/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1331 - val_accuracy: 0.7500\n",
      "Epoch 48/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1384 - val_accuracy: 0.7500\n",
      "Epoch 49/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1434 - val_accuracy: 0.7500\n",
      "Epoch 50/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1481 - val_accuracy: 0.7500\n",
      "Epoch 51/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1527 - val_accuracy: 0.7500\n",
      "Epoch 52/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.1571 - val_accuracy: 0.7500\n",
      "Epoch 53/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.1613 - val_accuracy: 0.7500\n",
      "Epoch 54/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.1653 - val_accuracy: 0.7500\n",
      "Epoch 55/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.1692 - val_accuracy: 0.7500\n",
      "Epoch 56/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1729 - val_accuracy: 0.7500\n",
      "Epoch 57/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1765 - val_accuracy: 0.7500\n",
      "Epoch 58/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1800 - val_accuracy: 0.7500\n",
      "Epoch 59/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1833 - val_accuracy: 0.7500\n",
      "Epoch 60/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1866 - val_accuracy: 0.7500\n",
      "Epoch 61/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1897 - val_accuracy: 0.7500\n",
      "Epoch 62/155\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1928 - val_accuracy: 0.7500\n",
      "Epoch 63/155\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1957 - val_accuracy: 0.7500\n",
      "Epoch 64/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1986 - val_accuracy: 0.7500\n",
      "Epoch 65/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2014 - val_accuracy: 0.7500\n",
      "Epoch 66/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2042 - val_accuracy: 0.7500\n",
      "Epoch 67/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2069 - val_accuracy: 0.7500\n",
      "Epoch 68/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2095 - val_accuracy: 0.7500\n",
      "Epoch 69/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2121 - val_accuracy: 0.7500\n",
      "Epoch 70/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2146 - val_accuracy: 0.7500\n",
      "Epoch 71/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2172 - val_accuracy: 0.7500\n",
      "Epoch 72/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2196 - val_accuracy: 0.7500\n",
      "Epoch 73/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2221 - val_accuracy: 0.7500\n",
      "Epoch 74/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2245 - val_accuracy: 0.7500\n",
      "Epoch 75/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2269 - val_accuracy: 0.7500\n",
      "Epoch 76/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2293 - val_accuracy: 0.7500\n",
      "Epoch 77/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2317 - val_accuracy: 0.7500\n",
      "Epoch 78/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2341 - val_accuracy: 0.7500\n",
      "Epoch 79/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2364 - val_accuracy: 0.7500\n",
      "Epoch 80/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2387 - val_accuracy: 0.7500\n",
      "Epoch 81/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2410 - val_accuracy: 0.7500\n",
      "Epoch 82/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2433 - val_accuracy: 0.7500\n",
      "Epoch 83/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2456 - val_accuracy: 0.7500\n",
      "Epoch 84/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2479 - val_accuracy: 0.7500\n",
      "Epoch 85/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2501 - val_accuracy: 0.7500\n",
      "Epoch 86/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2524 - val_accuracy: 0.7500\n",
      "Epoch 87/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2547 - val_accuracy: 0.7500\n",
      "Epoch 88/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2569 - val_accuracy: 0.7500\n",
      "Epoch 89/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2592 - val_accuracy: 0.7500\n",
      "Epoch 90/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2614 - val_accuracy: 0.7500\n",
      "Epoch 91/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2637 - val_accuracy: 0.7500\n",
      "Epoch 92/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2659 - val_accuracy: 0.7500\n",
      "Epoch 93/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2682 - val_accuracy: 0.7500\n",
      "Epoch 94/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2704 - val_accuracy: 0.7500\n",
      "Epoch 95/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2727 - val_accuracy: 0.7500\n",
      "Epoch 96/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2749 - val_accuracy: 0.7500\n",
      "Epoch 97/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2772 - val_accuracy: 0.7500\n",
      "Epoch 98/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2794 - val_accuracy: 0.7500\n",
      "Epoch 99/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2817 - val_accuracy: 0.7500\n",
      "Epoch 100/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2839 - val_accuracy: 0.7500\n",
      "Epoch 101/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2862 - val_accuracy: 0.7500\n",
      "Epoch 102/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2884 - val_accuracy: 0.7500\n",
      "Epoch 103/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2906 - val_accuracy: 0.7500\n",
      "Epoch 104/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2928 - val_accuracy: 0.7500\n",
      "Epoch 105/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2950 - val_accuracy: 0.7500\n",
      "Epoch 106/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2971 - val_accuracy: 0.7500\n",
      "Epoch 107/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2992 - val_accuracy: 0.7500\n",
      "Epoch 108/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3014 - val_accuracy: 0.7500\n",
      "Epoch 109/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3035 - val_accuracy: 0.7500\n",
      "Epoch 110/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3055 - val_accuracy: 0.7500\n",
      "Epoch 111/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3076 - val_accuracy: 0.7500\n",
      "Epoch 112/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3096 - val_accuracy: 0.7500\n",
      "Epoch 113/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3117 - val_accuracy: 0.7500\n",
      "Epoch 114/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3137 - val_accuracy: 0.7500\n",
      "Epoch 115/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3157 - val_accuracy: 0.7500\n",
      "Epoch 116/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3177 - val_accuracy: 0.7500\n",
      "Epoch 117/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3197 - val_accuracy: 0.7500\n",
      "Epoch 118/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3217 - val_accuracy: 0.7500\n",
      "Epoch 119/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3237 - val_accuracy: 0.7500\n",
      "Epoch 120/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3257 - val_accuracy: 0.7500\n",
      "Epoch 121/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3278 - val_accuracy: 0.7500\n",
      "Epoch 122/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3298 - val_accuracy: 0.7500\n",
      "Epoch 123/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3319 - val_accuracy: 0.7500\n",
      "Epoch 124/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3340 - val_accuracy: 0.7500\n",
      "Epoch 125/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3361 - val_accuracy: 0.7500\n",
      "Epoch 126/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3383 - val_accuracy: 0.7500\n",
      "Epoch 127/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3405 - val_accuracy: 0.7500\n",
      "Epoch 128/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3428 - val_accuracy: 0.7500\n",
      "Epoch 129/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3451 - val_accuracy: 0.7500\n",
      "Epoch 130/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3474 - val_accuracy: 0.7500\n",
      "Epoch 131/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3499 - val_accuracy: 0.6875\n",
      "Epoch 132/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3523 - val_accuracy: 0.6875\n",
      "Epoch 133/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3549 - val_accuracy: 0.6875\n",
      "Epoch 134/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3575 - val_accuracy: 0.6875\n",
      "Epoch 135/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.3602 - val_accuracy: 0.6875\n",
      "Epoch 136/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.3629 - val_accuracy: 0.6875\n",
      "Epoch 137/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.3658 - val_accuracy: 0.6875\n",
      "Epoch 138/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.3687 - val_accuracy: 0.6875\n",
      "Epoch 139/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.3716 - val_accuracy: 0.6875\n",
      "Epoch 140/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.3747 - val_accuracy: 0.6875\n",
      "Epoch 141/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 9.9666e-04 - accuracy: 1.0000 - val_loss: 1.3778 - val_accuracy: 0.6875\n",
      "Epoch 142/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.8900e-04 - accuracy: 1.0000 - val_loss: 1.3810 - val_accuracy: 0.6875\n",
      "Epoch 143/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.8144e-04 - accuracy: 1.0000 - val_loss: 1.3843 - val_accuracy: 0.6875\n",
      "Epoch 144/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 9.7397e-04 - accuracy: 1.0000 - val_loss: 1.3876 - val_accuracy: 0.6875\n",
      "Epoch 145/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.6659e-04 - accuracy: 1.0000 - val_loss: 1.3911 - val_accuracy: 0.6875\n",
      "Epoch 146/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.5930e-04 - accuracy: 1.0000 - val_loss: 1.3946 - val_accuracy: 0.6875\n",
      "Epoch 147/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 9.5210e-04 - accuracy: 1.0000 - val_loss: 1.3981 - val_accuracy: 0.6875\n",
      "Epoch 148/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.4499e-04 - accuracy: 1.0000 - val_loss: 1.4017 - val_accuracy: 0.6875\n",
      "Epoch 149/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.3795e-04 - accuracy: 1.0000 - val_loss: 1.4054 - val_accuracy: 0.6875\n",
      "Epoch 150/155\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 9.3100e-04 - accuracy: 1.0000 - val_loss: 1.4092 - val_accuracy: 0.6875\n",
      "Epoch 151/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.2414e-04 - accuracy: 1.0000 - val_loss: 1.4130 - val_accuracy: 0.6875\n",
      "Epoch 152/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 9.1735e-04 - accuracy: 1.0000 - val_loss: 1.4168 - val_accuracy: 0.6875\n",
      "Epoch 153/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 9.1064e-04 - accuracy: 1.0000 - val_loss: 1.4207 - val_accuracy: 0.6875\n",
      "Epoch 154/155\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 9.0401e-04 - accuracy: 1.0000 - val_loss: 1.4246 - val_accuracy: 0.6875\n",
      "Epoch 155/155\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 8.9746e-04 - accuracy: 1.0000 - val_loss: 1.4286 - val_accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 11:14:30,030] Trial 4 finished with values: [2.9047298431396484, 0.5] and parameters: {'epochs': 155, 'learning_rate': 0.1033479427005016, 'units': 2, 'two_layers': True, 'batch_size': 214}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/185\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 0.7029 - accuracy: 0.4219 - val_loss: 0.6664 - val_accuracy: 0.6250\n",
      "Epoch 2/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7611 - accuracy: 0.4219 - val_loss: 1.0750 - val_accuracy: 0.5000\n",
      "Epoch 3/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9258 - accuracy: 0.5781 - val_loss: 0.7153 - val_accuracy: 0.5000\n",
      "Epoch 4/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6824 - accuracy: 0.5781 - val_loss: 0.7512 - val_accuracy: 0.5000\n",
      "Epoch 5/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8049 - accuracy: 0.4219 - val_loss: 0.6967 - val_accuracy: 0.5000\n",
      "Epoch 6/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6834 - accuracy: 0.5781 - val_loss: 0.8947 - val_accuracy: 0.5000\n",
      "Epoch 7/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7921 - accuracy: 0.5781 - val_loss: 0.7064 - val_accuracy: 0.5000\n",
      "Epoch 8/185\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7328 - accuracy: 0.4219 - val_loss: 0.8018 - val_accuracy: 0.5000\n",
      "Epoch 9/185\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7277 - accuracy: 0.5781 - val_loss: 0.7662 - val_accuracy: 0.5000\n",
      "Epoch 10/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7177 - accuracy: 0.5781 - val_loss: 0.7098 - val_accuracy: 0.5000\n",
      "Epoch 11/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6811 - accuracy: 0.5781 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 12/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6928 - accuracy: 0.5469 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 13/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6976 - accuracy: 0.4219 - val_loss: 0.7042 - val_accuracy: 0.5000\n",
      "Epoch 14/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6862 - accuracy: 0.5781 - val_loss: 0.7326 - val_accuracy: 0.5000\n",
      "Epoch 15/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6887 - accuracy: 0.5781 - val_loss: 0.7059 - val_accuracy: 0.5000\n",
      "Epoch 16/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6808 - accuracy: 0.5781 - val_loss: 0.6985 - val_accuracy: 0.5000\n",
      "Epoch 17/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6823 - accuracy: 0.5781 - val_loss: 0.7009 - val_accuracy: 0.5000\n",
      "Epoch 18/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6814 - accuracy: 0.5781 - val_loss: 0.7080 - val_accuracy: 0.5000\n",
      "Epoch 19/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6810 - accuracy: 0.5781 - val_loss: 0.7147 - val_accuracy: 0.5000\n",
      "Epoch 20/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6822 - accuracy: 0.5781 - val_loss: 0.7143 - val_accuracy: 0.5000\n",
      "Epoch 21/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6821 - accuracy: 0.5781 - val_loss: 0.7078 - val_accuracy: 0.5000\n",
      "Epoch 22/185\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6810 - accuracy: 0.5781 - val_loss: 0.7016 - val_accuracy: 0.5000\n",
      "Epoch 23/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6813 - accuracy: 0.5781 - val_loss: 0.6994 - val_accuracy: 0.5000\n",
      "Epoch 24/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6819 - accuracy: 0.5781 - val_loss: 0.7013 - val_accuracy: 0.5000\n",
      "Epoch 25/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6814 - accuracy: 0.5781 - val_loss: 0.7065 - val_accuracy: 0.5000\n",
      "Epoch 26/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6809 - accuracy: 0.5781 - val_loss: 0.7115 - val_accuracy: 0.5000\n",
      "Epoch 27/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6815 - accuracy: 0.5781 - val_loss: 0.7116 - val_accuracy: 0.5000\n",
      "Epoch 28/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6815 - accuracy: 0.5781 - val_loss: 0.7070 - val_accuracy: 0.5000\n",
      "Epoch 29/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6810 - accuracy: 0.5781 - val_loss: 0.7024 - val_accuracy: 0.5000\n",
      "Epoch 30/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6811 - accuracy: 0.5781 - val_loss: 0.7009 - val_accuracy: 0.5000\n",
      "Epoch 31/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6814 - accuracy: 0.5781 - val_loss: 0.7028 - val_accuracy: 0.5000\n",
      "Epoch 32/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6811 - accuracy: 0.5781 - val_loss: 0.7070 - val_accuracy: 0.5000\n",
      "Epoch 33/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6809 - accuracy: 0.5781 - val_loss: 0.7101 - val_accuracy: 0.5000\n",
      "Epoch 34/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6812 - accuracy: 0.5781 - val_loss: 0.7091 - val_accuracy: 0.5000\n",
      "Epoch 35/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6811 - accuracy: 0.5781 - val_loss: 0.7054 - val_accuracy: 0.5000\n",
      "Epoch 36/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6809 - accuracy: 0.5781 - val_loss: 0.7025 - val_accuracy: 0.5000\n",
      "Epoch 37/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6811 - accuracy: 0.5781 - val_loss: 0.7024 - val_accuracy: 0.5000\n",
      "Epoch 38/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6811 - accuracy: 0.5781 - val_loss: 0.7049 - val_accuracy: 0.5000\n",
      "Epoch 39/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6808 - accuracy: 0.5781 - val_loss: 0.7080 - val_accuracy: 0.5000\n",
      "Epoch 40/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6808 - accuracy: 0.5781 - val_loss: 0.7091 - val_accuracy: 0.5000\n",
      "Epoch 41/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6802 - accuracy: 0.5781 - val_loss: 0.7094 - val_accuracy: 0.5000\n",
      "Epoch 42/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6752 - accuracy: 0.5781 - val_loss: 0.7530 - val_accuracy: 0.5000\n",
      "Epoch 43/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6771 - accuracy: 0.5781 - val_loss: 0.6899 - val_accuracy: 0.5000\n",
      "Epoch 44/185\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6821 - accuracy: 0.5781 - val_loss: 0.6948 - val_accuracy: 0.5000\n",
      "Epoch 45/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6829 - accuracy: 0.5781 - val_loss: 0.7007 - val_accuracy: 0.5000\n",
      "Epoch 46/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6740 - accuracy: 0.5781 - val_loss: 0.7552 - val_accuracy: 0.5000\n",
      "Epoch 47/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6649 - accuracy: 0.5781 - val_loss: 0.8849 - val_accuracy: 0.4375\n",
      "Epoch 48/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6612 - accuracy: 0.5781 - val_loss: 0.9258 - val_accuracy: 0.4375\n",
      "Epoch 49/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6388 - accuracy: 0.5781 - val_loss: 0.9414 - val_accuracy: 0.2500\n",
      "Epoch 50/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6186 - accuracy: 0.6719 - val_loss: 0.9298 - val_accuracy: 0.2500\n",
      "Epoch 51/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5723 - accuracy: 0.7344 - val_loss: 0.9690 - val_accuracy: 0.2500\n",
      "Epoch 52/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5711 - accuracy: 0.7500 - val_loss: 0.9898 - val_accuracy: 0.2500\n",
      "Epoch 53/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5829 - accuracy: 0.7188 - val_loss: 1.0011 - val_accuracy: 0.2500\n",
      "Epoch 54/185\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5365 - accuracy: 0.7344 - val_loss: 1.1090 - val_accuracy: 0.2500\n",
      "Epoch 55/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5405 - accuracy: 0.7344 - val_loss: 1.0907 - val_accuracy: 0.2500\n",
      "Epoch 56/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4696 - accuracy: 0.7812 - val_loss: 0.9673 - val_accuracy: 0.3125\n",
      "Epoch 57/185\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5080 - accuracy: 0.7812 - val_loss: 0.9177 - val_accuracy: 0.3750\n",
      "Epoch 58/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4490 - accuracy: 0.8281 - val_loss: 1.1874 - val_accuracy: 0.4375\n",
      "Epoch 59/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4460 - accuracy: 0.8281 - val_loss: 1.2849 - val_accuracy: 0.3125\n",
      "Epoch 60/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4215 - accuracy: 0.7812 - val_loss: 1.3812 - val_accuracy: 0.3125\n",
      "Epoch 61/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3868 - accuracy: 0.8281 - val_loss: 1.6703 - val_accuracy: 0.3125\n",
      "Epoch 62/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9547 - accuracy: 0.6094 - val_loss: 1.6090 - val_accuracy: 0.4375\n",
      "Epoch 63/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7890 - accuracy: 0.7188 - val_loss: 0.9584 - val_accuracy: 0.5625\n",
      "Epoch 64/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6761 - accuracy: 0.7031 - val_loss: 1.2633 - val_accuracy: 0.3125\n",
      "Epoch 65/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5564 - accuracy: 0.7031 - val_loss: 1.3946 - val_accuracy: 0.4375\n",
      "Epoch 66/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5172 - accuracy: 0.6406 - val_loss: 1.2911 - val_accuracy: 0.3750\n",
      "Epoch 67/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5764 - accuracy: 0.5625 - val_loss: 1.1959 - val_accuracy: 0.4375\n",
      "Epoch 68/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5600 - accuracy: 0.5312 - val_loss: 1.0156 - val_accuracy: 0.3750\n",
      "Epoch 69/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5347 - accuracy: 0.6719 - val_loss: 1.0672 - val_accuracy: 0.3750\n",
      "Epoch 70/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5370 - accuracy: 0.6875 - val_loss: 0.9435 - val_accuracy: 0.3750\n",
      "Epoch 71/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5360 - accuracy: 0.7031 - val_loss: 0.8769 - val_accuracy: 0.5000\n",
      "Epoch 72/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5069 - accuracy: 0.7031 - val_loss: 0.9783 - val_accuracy: 0.5000\n",
      "Epoch 73/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5401 - accuracy: 0.6562 - val_loss: 1.0313 - val_accuracy: 0.4375\n",
      "Epoch 74/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5120 - accuracy: 0.6719 - val_loss: 0.9110 - val_accuracy: 0.3750\n",
      "Epoch 75/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4879 - accuracy: 0.6875 - val_loss: 0.9395 - val_accuracy: 0.3125\n",
      "Epoch 76/185\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5051 - accuracy: 0.7031 - val_loss: 0.9420 - val_accuracy: 0.3750\n",
      "Epoch 77/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5142 - accuracy: 0.7031 - val_loss: 0.9286 - val_accuracy: 0.4375\n",
      "Epoch 78/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5054 - accuracy: 0.7031 - val_loss: 0.9164 - val_accuracy: 0.4375\n",
      "Epoch 79/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4846 - accuracy: 0.7344 - val_loss: 0.9063 - val_accuracy: 0.4375\n",
      "Epoch 80/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4866 - accuracy: 0.7344 - val_loss: 0.8858 - val_accuracy: 0.4375\n",
      "Epoch 81/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4826 - accuracy: 0.7500 - val_loss: 0.9331 - val_accuracy: 0.4375\n",
      "Epoch 82/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4656 - accuracy: 0.7656 - val_loss: 0.8584 - val_accuracy: 0.5000\n",
      "Epoch 83/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4679 - accuracy: 0.7500 - val_loss: 0.8825 - val_accuracy: 0.5000\n",
      "Epoch 84/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4669 - accuracy: 0.7500 - val_loss: 0.9068 - val_accuracy: 0.5000\n",
      "Epoch 85/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4772 - accuracy: 0.7344 - val_loss: 0.9203 - val_accuracy: 0.4375\n",
      "Epoch 86/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4733 - accuracy: 0.7500 - val_loss: 0.9416 - val_accuracy: 0.4375\n",
      "Epoch 87/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4617 - accuracy: 0.7500 - val_loss: 0.9205 - val_accuracy: 0.5000\n",
      "Epoch 88/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4569 - accuracy: 0.7500 - val_loss: 0.9427 - val_accuracy: 0.5000\n",
      "Epoch 89/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4512 - accuracy: 0.7500 - val_loss: 1.0002 - val_accuracy: 0.4375\n",
      "Epoch 90/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4484 - accuracy: 0.7500 - val_loss: 0.9950 - val_accuracy: 0.4375\n",
      "Epoch 91/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4380 - accuracy: 0.7500 - val_loss: 0.9860 - val_accuracy: 0.4375\n",
      "Epoch 92/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4483 - accuracy: 0.7500 - val_loss: 0.9826 - val_accuracy: 0.5000\n",
      "Epoch 93/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4493 - accuracy: 0.7500 - val_loss: 0.9983 - val_accuracy: 0.5000\n",
      "Epoch 94/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4444 - accuracy: 0.7500 - val_loss: 0.9786 - val_accuracy: 0.5000\n",
      "Epoch 95/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4357 - accuracy: 0.7656 - val_loss: 0.9723 - val_accuracy: 0.5000\n",
      "Epoch 96/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4350 - accuracy: 0.7656 - val_loss: 0.9782 - val_accuracy: 0.5000\n",
      "Epoch 97/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4350 - accuracy: 0.7656 - val_loss: 0.9899 - val_accuracy: 0.5000\n",
      "Epoch 98/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4300 - accuracy: 0.7812 - val_loss: 1.0217 - val_accuracy: 0.5000\n",
      "Epoch 99/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4208 - accuracy: 0.7812 - val_loss: 1.0424 - val_accuracy: 0.5000\n",
      "Epoch 100/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4238 - accuracy: 0.7656 - val_loss: 1.0362 - val_accuracy: 0.5000\n",
      "Epoch 101/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4215 - accuracy: 0.7812 - val_loss: 1.0113 - val_accuracy: 0.5625\n",
      "Epoch 102/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4243 - accuracy: 0.7656 - val_loss: 0.9862 - val_accuracy: 0.5625\n",
      "Epoch 103/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4144 - accuracy: 0.7812 - val_loss: 0.9711 - val_accuracy: 0.6250\n",
      "Epoch 104/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4137 - accuracy: 0.7812 - val_loss: 0.9706 - val_accuracy: 0.6250\n",
      "Epoch 105/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4304 - accuracy: 0.7656 - val_loss: 0.9810 - val_accuracy: 0.6250\n",
      "Epoch 106/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4301 - accuracy: 0.7656 - val_loss: 0.9961 - val_accuracy: 0.6250\n",
      "Epoch 107/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4245 - accuracy: 0.7656 - val_loss: 1.0071 - val_accuracy: 0.6250\n",
      "Epoch 108/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4030 - accuracy: 0.7812 - val_loss: 1.0179 - val_accuracy: 0.6250\n",
      "Epoch 109/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4133 - accuracy: 0.7656 - val_loss: 1.0867 - val_accuracy: 0.5625\n",
      "Epoch 110/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4084 - accuracy: 0.7812 - val_loss: 1.0991 - val_accuracy: 0.5000\n",
      "Epoch 111/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4091 - accuracy: 0.7656 - val_loss: 1.0554 - val_accuracy: 0.5000\n",
      "Epoch 112/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4088 - accuracy: 0.7656 - val_loss: 1.0755 - val_accuracy: 0.5000\n",
      "Epoch 113/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3987 - accuracy: 0.7812 - val_loss: 1.0921 - val_accuracy: 0.5000\n",
      "Epoch 114/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3979 - accuracy: 0.7812 - val_loss: 1.1008 - val_accuracy: 0.5000\n",
      "Epoch 115/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3973 - accuracy: 0.7812 - val_loss: 1.1538 - val_accuracy: 0.5000\n",
      "Epoch 116/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3949 - accuracy: 0.7812 - val_loss: 1.1527 - val_accuracy: 0.5000\n",
      "Epoch 117/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3953 - accuracy: 0.7812 - val_loss: 1.1314 - val_accuracy: 0.5000\n",
      "Epoch 118/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3947 - accuracy: 0.7812 - val_loss: 1.1757 - val_accuracy: 0.4375\n",
      "Epoch 119/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3954 - accuracy: 0.7812 - val_loss: 1.1720 - val_accuracy: 0.4375\n",
      "Epoch 120/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3958 - accuracy: 0.7812 - val_loss: 1.1548 - val_accuracy: 0.5000\n",
      "Epoch 121/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3940 - accuracy: 0.7812 - val_loss: 1.1483 - val_accuracy: 0.5000\n",
      "Epoch 122/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3932 - accuracy: 0.7812 - val_loss: 1.1514 - val_accuracy: 0.5000\n",
      "Epoch 123/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3926 - accuracy: 0.7812 - val_loss: 1.1552 - val_accuracy: 0.5000\n",
      "Epoch 124/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3921 - accuracy: 0.7812 - val_loss: 1.1594 - val_accuracy: 0.5000\n",
      "Epoch 125/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3917 - accuracy: 0.7812 - val_loss: 1.1640 - val_accuracy: 0.5000\n",
      "Epoch 126/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3913 - accuracy: 0.7812 - val_loss: 1.1674 - val_accuracy: 0.5000\n",
      "Epoch 127/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3910 - accuracy: 0.7812 - val_loss: 1.1737 - val_accuracy: 0.5000\n",
      "Epoch 128/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3907 - accuracy: 0.7812 - val_loss: 1.1810 - val_accuracy: 0.5000\n",
      "Epoch 129/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3904 - accuracy: 0.7812 - val_loss: 1.1984 - val_accuracy: 0.5000\n",
      "Epoch 130/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3902 - accuracy: 0.7812 - val_loss: 1.2254 - val_accuracy: 0.4375\n",
      "Epoch 131/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3899 - accuracy: 0.7812 - val_loss: 1.1986 - val_accuracy: 0.5000\n",
      "Epoch 132/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3897 - accuracy: 0.7812 - val_loss: 1.2034 - val_accuracy: 0.5000\n",
      "Epoch 133/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3895 - accuracy: 0.7812 - val_loss: 1.2083 - val_accuracy: 0.5000\n",
      "Epoch 134/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3893 - accuracy: 0.7812 - val_loss: 1.2132 - val_accuracy: 0.5000\n",
      "Epoch 135/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4010 - accuracy: 0.7656 - val_loss: 0.9714 - val_accuracy: 0.6250\n",
      "Epoch 136/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3896 - accuracy: 0.7812 - val_loss: 1.1745 - val_accuracy: 0.5625\n",
      "Epoch 137/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4534 - accuracy: 0.7656 - val_loss: 1.0345 - val_accuracy: 0.6250\n",
      "Epoch 138/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4731 - accuracy: 0.7500 - val_loss: 1.1747 - val_accuracy: 0.5625\n",
      "Epoch 139/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5105 - accuracy: 0.7188 - val_loss: 1.1561 - val_accuracy: 0.5625\n",
      "Epoch 140/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5043 - accuracy: 0.7188 - val_loss: 1.0956 - val_accuracy: 0.5625\n",
      "Epoch 141/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5303 - accuracy: 0.7031 - val_loss: 1.0861 - val_accuracy: 0.5625\n",
      "Epoch 142/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4928 - accuracy: 0.7031 - val_loss: 1.0828 - val_accuracy: 0.5625\n",
      "Epoch 143/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4727 - accuracy: 0.7188 - val_loss: 1.0773 - val_accuracy: 0.6250\n",
      "Epoch 144/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4510 - accuracy: 0.7344 - val_loss: 1.0760 - val_accuracy: 0.6250\n",
      "Epoch 145/185\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4385 - accuracy: 0.7656 - val_loss: 1.1290 - val_accuracy: 0.5625\n",
      "Epoch 146/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4408 - accuracy: 0.7656 - val_loss: 1.1540 - val_accuracy: 0.5000\n",
      "Epoch 147/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4506 - accuracy: 0.7344 - val_loss: 1.1709 - val_accuracy: 0.5000\n",
      "Epoch 148/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4532 - accuracy: 0.7344 - val_loss: 1.1656 - val_accuracy: 0.5000\n",
      "Epoch 149/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4567 - accuracy: 0.7344 - val_loss: 1.1773 - val_accuracy: 0.5000\n",
      "Epoch 150/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4548 - accuracy: 0.7344 - val_loss: 1.2021 - val_accuracy: 0.5000\n",
      "Epoch 151/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4540 - accuracy: 0.7344 - val_loss: 1.2253 - val_accuracy: 0.5000\n",
      "Epoch 152/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4514 - accuracy: 0.7344 - val_loss: 1.1988 - val_accuracy: 0.5000\n",
      "Epoch 153/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4491 - accuracy: 0.7344 - val_loss: 1.1948 - val_accuracy: 0.5000\n",
      "Epoch 154/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4464 - accuracy: 0.7344 - val_loss: 1.1893 - val_accuracy: 0.5000\n",
      "Epoch 155/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4435 - accuracy: 0.7344 - val_loss: 1.1876 - val_accuracy: 0.5625\n",
      "Epoch 156/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4408 - accuracy: 0.7656 - val_loss: 1.1769 - val_accuracy: 0.5625\n",
      "Epoch 157/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4384 - accuracy: 0.7656 - val_loss: 1.1873 - val_accuracy: 0.5625\n",
      "Epoch 158/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4362 - accuracy: 0.7656 - val_loss: 1.1794 - val_accuracy: 0.5625\n",
      "Epoch 159/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4341 - accuracy: 0.7656 - val_loss: 1.0999 - val_accuracy: 0.6250\n",
      "Epoch 160/185\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4314 - accuracy: 0.7656 - val_loss: 1.0883 - val_accuracy: 0.6250\n",
      "Epoch 161/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4282 - accuracy: 0.7656 - val_loss: 1.0800 - val_accuracy: 0.6250\n",
      "Epoch 162/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4265 - accuracy: 0.7656 - val_loss: 1.0738 - val_accuracy: 0.6250\n",
      "Epoch 163/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4254 - accuracy: 0.7656 - val_loss: 1.1843 - val_accuracy: 0.5625\n",
      "Epoch 164/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4245 - accuracy: 0.7656 - val_loss: 1.1732 - val_accuracy: 0.5625\n",
      "Epoch 165/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4237 - accuracy: 0.7656 - val_loss: 1.0649 - val_accuracy: 0.6250\n",
      "Epoch 166/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4227 - accuracy: 0.7656 - val_loss: 1.0641 - val_accuracy: 0.6250\n",
      "Epoch 167/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4218 - accuracy: 0.7656 - val_loss: 1.2101 - val_accuracy: 0.5625\n",
      "Epoch 168/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4209 - accuracy: 0.7656 - val_loss: 1.2151 - val_accuracy: 0.5625\n",
      "Epoch 169/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4200 - accuracy: 0.7656 - val_loss: 1.2203 - val_accuracy: 0.5625\n",
      "Epoch 170/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4193 - accuracy: 0.7656 - val_loss: 1.2260 - val_accuracy: 0.5625\n",
      "Epoch 171/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4191 - accuracy: 0.7656 - val_loss: 1.2320 - val_accuracy: 0.5625\n",
      "Epoch 172/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4177 - accuracy: 0.7656 - val_loss: 1.2323 - val_accuracy: 0.5625\n",
      "Epoch 173/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4170 - accuracy: 0.7656 - val_loss: 1.2374 - val_accuracy: 0.5625\n",
      "Epoch 174/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4164 - accuracy: 0.7656 - val_loss: 1.2431 - val_accuracy: 0.5625\n",
      "Epoch 175/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4158 - accuracy: 0.7656 - val_loss: 1.2489 - val_accuracy: 0.5625\n",
      "Epoch 176/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4153 - accuracy: 0.7656 - val_loss: 1.2547 - val_accuracy: 0.5625\n",
      "Epoch 177/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4148 - accuracy: 0.7656 - val_loss: 1.2605 - val_accuracy: 0.5625\n",
      "Epoch 178/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4144 - accuracy: 0.7656 - val_loss: 1.2663 - val_accuracy: 0.5625\n",
      "Epoch 179/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4140 - accuracy: 0.7656 - val_loss: 1.2721 - val_accuracy: 0.5625\n",
      "Epoch 180/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4136 - accuracy: 0.7656 - val_loss: 1.2777 - val_accuracy: 0.5625\n",
      "Epoch 181/185\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4133 - accuracy: 0.7656 - val_loss: 1.2831 - val_accuracy: 0.5000\n",
      "Epoch 182/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4130 - accuracy: 0.7656 - val_loss: 1.2882 - val_accuracy: 0.5000\n",
      "Epoch 183/185\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4128 - accuracy: 0.7656 - val_loss: 1.2933 - val_accuracy: 0.5000\n",
      "Epoch 184/185\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4125 - accuracy: 0.7656 - val_loss: 1.2981 - val_accuracy: 0.5000\n",
      "Epoch 185/185\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4123 - accuracy: 0.7656 - val_loss: 1.3028 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 11:14:34,477] Trial 5 finished with values: [0.8500313758850098, 0.44999998807907104] and parameters: {'epochs': 185, 'learning_rate': 0.2331602054604137, 'units': 10, 'two_layers': True, 'batch_size': 110}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/186\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.6851 - accuracy: 0.5312 - val_loss: 0.6769 - val_accuracy: 0.5625\n",
      "Epoch 2/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6270 - accuracy: 0.6406 - val_loss: 0.6806 - val_accuracy: 0.5625\n",
      "Epoch 3/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5651 - accuracy: 0.7656 - val_loss: 0.6876 - val_accuracy: 0.5625\n",
      "Epoch 4/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5077 - accuracy: 0.9375 - val_loss: 0.7009 - val_accuracy: 0.4375\n",
      "Epoch 5/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4666 - accuracy: 0.9375 - val_loss: 0.7075 - val_accuracy: 0.3750\n",
      "Epoch 6/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4257 - accuracy: 0.9375 - val_loss: 0.7099 - val_accuracy: 0.5000\n",
      "Epoch 7/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3868 - accuracy: 0.9688 - val_loss: 0.7142 - val_accuracy: 0.5625\n",
      "Epoch 8/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3542 - accuracy: 0.9844 - val_loss: 0.7224 - val_accuracy: 0.5625\n",
      "Epoch 9/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3294 - accuracy: 0.9844 - val_loss: 0.7320 - val_accuracy: 0.5625\n",
      "Epoch 10/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3077 - accuracy: 0.9844 - val_loss: 0.7399 - val_accuracy: 0.5625\n",
      "Epoch 11/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2875 - accuracy: 0.9844 - val_loss: 0.7440 - val_accuracy: 0.5625\n",
      "Epoch 12/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2684 - accuracy: 0.9844 - val_loss: 0.7444 - val_accuracy: 0.6250\n",
      "Epoch 13/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2507 - accuracy: 1.0000 - val_loss: 0.7454 - val_accuracy: 0.6250\n",
      "Epoch 14/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2361 - accuracy: 1.0000 - val_loss: 0.7511 - val_accuracy: 0.5625\n",
      "Epoch 15/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2240 - accuracy: 1.0000 - val_loss: 0.7609 - val_accuracy: 0.5625\n",
      "Epoch 16/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.7725 - val_accuracy: 0.5625\n",
      "Epoch 17/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2020 - accuracy: 1.0000 - val_loss: 0.7850 - val_accuracy: 0.5625\n",
      "Epoch 18/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1920 - accuracy: 1.0000 - val_loss: 0.7989 - val_accuracy: 0.5000\n",
      "Epoch 19/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1829 - accuracy: 1.0000 - val_loss: 0.8149 - val_accuracy: 0.5000\n",
      "Epoch 20/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1745 - accuracy: 1.0000 - val_loss: 0.8325 - val_accuracy: 0.4375\n",
      "Epoch 21/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1668 - accuracy: 1.0000 - val_loss: 0.8504 - val_accuracy: 0.5625\n",
      "Epoch 22/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1596 - accuracy: 1.0000 - val_loss: 0.8677 - val_accuracy: 0.5625\n",
      "Epoch 23/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1530 - accuracy: 1.0000 - val_loss: 0.8846 - val_accuracy: 0.5625\n",
      "Epoch 24/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1467 - accuracy: 1.0000 - val_loss: 0.9012 - val_accuracy: 0.5625\n",
      "Epoch 25/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1409 - accuracy: 1.0000 - val_loss: 0.9176 - val_accuracy: 0.5625\n",
      "Epoch 26/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1353 - accuracy: 1.0000 - val_loss: 0.9336 - val_accuracy: 0.5625\n",
      "Epoch 27/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1301 - accuracy: 1.0000 - val_loss: 0.9491 - val_accuracy: 0.5625\n",
      "Epoch 28/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1252 - accuracy: 1.0000 - val_loss: 0.9641 - val_accuracy: 0.5625\n",
      "Epoch 29/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1205 - accuracy: 1.0000 - val_loss: 0.9785 - val_accuracy: 0.5625\n",
      "Epoch 30/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1161 - accuracy: 1.0000 - val_loss: 0.9924 - val_accuracy: 0.5625\n",
      "Epoch 31/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1119 - accuracy: 1.0000 - val_loss: 1.0059 - val_accuracy: 0.5625\n",
      "Epoch 32/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1079 - accuracy: 1.0000 - val_loss: 1.0191 - val_accuracy: 0.5625\n",
      "Epoch 33/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1042 - accuracy: 1.0000 - val_loss: 1.0320 - val_accuracy: 0.5625\n",
      "Epoch 34/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1006 - accuracy: 1.0000 - val_loss: 1.0447 - val_accuracy: 0.5625\n",
      "Epoch 35/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0971 - accuracy: 1.0000 - val_loss: 1.0571 - val_accuracy: 0.5625\n",
      "Epoch 36/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0939 - accuracy: 1.0000 - val_loss: 1.0693 - val_accuracy: 0.5625\n",
      "Epoch 37/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0908 - accuracy: 1.0000 - val_loss: 1.0814 - val_accuracy: 0.5625\n",
      "Epoch 38/186\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0879 - accuracy: 1.0000 - val_loss: 1.0932 - val_accuracy: 0.5625\n",
      "Epoch 39/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0851 - accuracy: 1.0000 - val_loss: 1.1049 - val_accuracy: 0.5625\n",
      "Epoch 40/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0825 - accuracy: 1.0000 - val_loss: 1.1163 - val_accuracy: 0.5625\n",
      "Epoch 41/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0799 - accuracy: 1.0000 - val_loss: 1.1276 - val_accuracy: 0.5625\n",
      "Epoch 42/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0774 - accuracy: 1.0000 - val_loss: 1.1387 - val_accuracy: 0.5625\n",
      "Epoch 43/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 1.1496 - val_accuracy: 0.5625\n",
      "Epoch 44/186\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0729 - accuracy: 1.0000 - val_loss: 1.1605 - val_accuracy: 0.5625\n",
      "Epoch 45/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 1.1712 - val_accuracy: 0.5625\n",
      "Epoch 46/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 1.1817 - val_accuracy: 0.5625\n",
      "Epoch 47/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 1.1922 - val_accuracy: 0.5625\n",
      "Epoch 48/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 1.2025 - val_accuracy: 0.5625\n",
      "Epoch 49/186\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 1.2127 - val_accuracy: 0.5625\n",
      "Epoch 50/186\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 1.2228 - val_accuracy: 0.5625\n",
      "Epoch 51/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 1.2327 - val_accuracy: 0.5625\n",
      "Epoch 52/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 1.2426 - val_accuracy: 0.5625\n",
      "Epoch 53/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 1.2523 - val_accuracy: 0.5625\n",
      "Epoch 54/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 1.2618 - val_accuracy: 0.5625\n",
      "Epoch 55/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 1.2713 - val_accuracy: 0.5625\n",
      "Epoch 56/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 1.2806 - val_accuracy: 0.5625\n",
      "Epoch 57/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 1.2898 - val_accuracy: 0.5625\n",
      "Epoch 58/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 1.2989 - val_accuracy: 0.5625\n",
      "Epoch 59/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 1.3079 - val_accuracy: 0.5625\n",
      "Epoch 60/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 1.3168 - val_accuracy: 0.5625\n",
      "Epoch 61/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 1.3255 - val_accuracy: 0.5625\n",
      "Epoch 62/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 1.3342 - val_accuracy: 0.5625\n",
      "Epoch 63/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 1.3427 - val_accuracy: 0.5625\n",
      "Epoch 64/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 1.3511 - val_accuracy: 0.5625\n",
      "Epoch 65/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 1.3594 - val_accuracy: 0.5625\n",
      "Epoch 66/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 1.3676 - val_accuracy: 0.5625\n",
      "Epoch 67/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 1.3757 - val_accuracy: 0.5625\n",
      "Epoch 68/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 1.3837 - val_accuracy: 0.5625\n",
      "Epoch 69/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 1.3915 - val_accuracy: 0.5625\n",
      "Epoch 70/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 1.3993 - val_accuracy: 0.5625\n",
      "Epoch 71/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 1.4069 - val_accuracy: 0.5625\n",
      "Epoch 72/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 1.4145 - val_accuracy: 0.5625\n",
      "Epoch 73/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 1.4219 - val_accuracy: 0.5625\n",
      "Epoch 74/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 1.4293 - val_accuracy: 0.5625\n",
      "Epoch 75/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 1.4366 - val_accuracy: 0.5625\n",
      "Epoch 76/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 1.4437 - val_accuracy: 0.5625\n",
      "Epoch 77/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 1.4508 - val_accuracy: 0.5625\n",
      "Epoch 78/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 1.4578 - val_accuracy: 0.5625\n",
      "Epoch 79/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 1.4647 - val_accuracy: 0.5625\n",
      "Epoch 80/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 1.4715 - val_accuracy: 0.5625\n",
      "Epoch 81/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 1.4783 - val_accuracy: 0.5625\n",
      "Epoch 82/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 1.4849 - val_accuracy: 0.5625\n",
      "Epoch 83/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 1.4915 - val_accuracy: 0.5625\n",
      "Epoch 84/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 1.4980 - val_accuracy: 0.5625\n",
      "Epoch 85/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 1.5044 - val_accuracy: 0.5625\n",
      "Epoch 86/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 1.5108 - val_accuracy: 0.5625\n",
      "Epoch 87/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 1.5170 - val_accuracy: 0.5625\n",
      "Epoch 88/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 1.5232 - val_accuracy: 0.5625\n",
      "Epoch 89/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 1.5293 - val_accuracy: 0.5625\n",
      "Epoch 90/186\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 1.5354 - val_accuracy: 0.5625\n",
      "Epoch 91/186\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 1.5413 - val_accuracy: 0.5625\n",
      "Epoch 92/186\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 1.5473 - val_accuracy: 0.5625\n",
      "Epoch 93/186\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 1.5531 - val_accuracy: 0.5625\n",
      "Epoch 94/186\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 1.5589 - val_accuracy: 0.5625\n",
      "Epoch 95/186\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 1.5646 - val_accuracy: 0.5625\n",
      "Epoch 96/186\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 1.5702 - val_accuracy: 0.5625\n",
      "Epoch 97/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 1.5758 - val_accuracy: 0.5625\n",
      "Epoch 98/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 1.5814 - val_accuracy: 0.5625\n",
      "Epoch 99/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 1.5868 - val_accuracy: 0.5625\n",
      "Epoch 100/186\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.5923 - val_accuracy: 0.5625\n",
      "Epoch 101/186\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 1.5976 - val_accuracy: 0.5625\n",
      "Epoch 102/186\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 1.6029 - val_accuracy: 0.5625\n",
      "Epoch 103/186\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 1.6082 - val_accuracy: 0.5625\n",
      "Epoch 104/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 1.6134 - val_accuracy: 0.5625\n",
      "Epoch 105/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 1.6185 - val_accuracy: 0.5625\n",
      "Epoch 106/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 1.6237 - val_accuracy: 0.5625\n",
      "Epoch 107/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 1.6287 - val_accuracy: 0.5625\n",
      "Epoch 108/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 1.6337 - val_accuracy: 0.5625\n",
      "Epoch 109/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 1.6387 - val_accuracy: 0.5625\n",
      "Epoch 110/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 1.6436 - val_accuracy: 0.5625\n",
      "Epoch 111/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 1.6485 - val_accuracy: 0.5625\n",
      "Epoch 112/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.6533 - val_accuracy: 0.5625\n",
      "Epoch 113/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.6581 - val_accuracy: 0.5625\n",
      "Epoch 114/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.6629 - val_accuracy: 0.5625\n",
      "Epoch 115/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 1.6676 - val_accuracy: 0.5625\n",
      "Epoch 116/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.6723 - val_accuracy: 0.5625\n",
      "Epoch 117/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.6769 - val_accuracy: 0.5625\n",
      "Epoch 118/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.6815 - val_accuracy: 0.5625\n",
      "Epoch 119/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 1.6860 - val_accuracy: 0.5625\n",
      "Epoch 120/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.6906 - val_accuracy: 0.5625\n",
      "Epoch 121/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.6950 - val_accuracy: 0.5625\n",
      "Epoch 122/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 1.6995 - val_accuracy: 0.5625\n",
      "Epoch 123/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 1.7039 - val_accuracy: 0.5625\n",
      "Epoch 124/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.7083 - val_accuracy: 0.5625\n",
      "Epoch 125/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.7126 - val_accuracy: 0.5625\n",
      "Epoch 126/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 1.7170 - val_accuracy: 0.5625\n",
      "Epoch 127/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.7212 - val_accuracy: 0.5625\n",
      "Epoch 128/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.7255 - val_accuracy: 0.5625\n",
      "Epoch 129/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.7297 - val_accuracy: 0.5625\n",
      "Epoch 130/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.7339 - val_accuracy: 0.5625\n",
      "Epoch 131/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.7381 - val_accuracy: 0.5625\n",
      "Epoch 132/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.7422 - val_accuracy: 0.5625\n",
      "Epoch 133/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.7463 - val_accuracy: 0.5625\n",
      "Epoch 134/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.7504 - val_accuracy: 0.5625\n",
      "Epoch 135/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.7544 - val_accuracy: 0.5625\n",
      "Epoch 136/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.7584 - val_accuracy: 0.5625\n",
      "Epoch 137/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.7624 - val_accuracy: 0.5625\n",
      "Epoch 138/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.7664 - val_accuracy: 0.5625\n",
      "Epoch 139/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.7703 - val_accuracy: 0.5625\n",
      "Epoch 140/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.7743 - val_accuracy: 0.5625\n",
      "Epoch 141/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.7781 - val_accuracy: 0.5625\n",
      "Epoch 142/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.7820 - val_accuracy: 0.5625\n",
      "Epoch 143/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.7858 - val_accuracy: 0.5625\n",
      "Epoch 144/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.7897 - val_accuracy: 0.5625\n",
      "Epoch 145/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.7934 - val_accuracy: 0.5625\n",
      "Epoch 146/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.7972 - val_accuracy: 0.5625\n",
      "Epoch 147/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.8009 - val_accuracy: 0.5625\n",
      "Epoch 148/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.8047 - val_accuracy: 0.5625\n",
      "Epoch 149/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.8084 - val_accuracy: 0.5625\n",
      "Epoch 150/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.8120 - val_accuracy: 0.5625\n",
      "Epoch 151/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.8157 - val_accuracy: 0.5625\n",
      "Epoch 152/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.8193 - val_accuracy: 0.5625\n",
      "Epoch 153/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.8229 - val_accuracy: 0.5625\n",
      "Epoch 154/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.8265 - val_accuracy: 0.5625\n",
      "Epoch 155/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.8301 - val_accuracy: 0.5625\n",
      "Epoch 156/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.8336 - val_accuracy: 0.5625\n",
      "Epoch 157/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.8372 - val_accuracy: 0.5625\n",
      "Epoch 158/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.8407 - val_accuracy: 0.5625\n",
      "Epoch 159/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.8442 - val_accuracy: 0.5625\n",
      "Epoch 160/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.8476 - val_accuracy: 0.5625\n",
      "Epoch 161/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.8511 - val_accuracy: 0.5625\n",
      "Epoch 162/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.8545 - val_accuracy: 0.5625\n",
      "Epoch 163/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.8579 - val_accuracy: 0.5625\n",
      "Epoch 164/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.8613 - val_accuracy: 0.5625\n",
      "Epoch 165/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.8647 - val_accuracy: 0.5625\n",
      "Epoch 166/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.8681 - val_accuracy: 0.5625\n",
      "Epoch 167/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.8714 - val_accuracy: 0.5625\n",
      "Epoch 168/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.8747 - val_accuracy: 0.5625\n",
      "Epoch 169/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.8780 - val_accuracy: 0.5625\n",
      "Epoch 170/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.8813 - val_accuracy: 0.5625\n",
      "Epoch 171/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.8846 - val_accuracy: 0.5625\n",
      "Epoch 172/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.8878 - val_accuracy: 0.5625\n",
      "Epoch 173/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.8911 - val_accuracy: 0.5625\n",
      "Epoch 174/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.8943 - val_accuracy: 0.5625\n",
      "Epoch 175/186\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.8975 - val_accuracy: 0.5625\n",
      "Epoch 176/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.9007 - val_accuracy: 0.5625\n",
      "Epoch 177/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.9039 - val_accuracy: 0.5625\n",
      "Epoch 178/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.9070 - val_accuracy: 0.5625\n",
      "Epoch 179/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.9102 - val_accuracy: 0.5625\n",
      "Epoch 180/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.9133 - val_accuracy: 0.5625\n",
      "Epoch 181/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.9164 - val_accuracy: 0.5625\n",
      "Epoch 182/186\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.9195 - val_accuracy: 0.5625\n",
      "Epoch 183/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.9226 - val_accuracy: 0.5625\n",
      "Epoch 184/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.9256 - val_accuracy: 0.5625\n",
      "Epoch 185/186\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.9287 - val_accuracy: 0.5625\n",
      "Epoch 186/186\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.9317 - val_accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 11:14:38,526] Trial 6 finished with values: [1.9973602294921875, 0.550000011920929] and parameters: {'epochs': 186, 'learning_rate': 0.013113326216161444, 'units': 2, 'two_layers': False, 'batch_size': 111}.\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T09:14:47.929184Z",
     "start_time": "2025-06-18T09:14:47.917166Z"
    }
   },
   "cell_type": "code",
   "source": "rnn_emb_params",
   "id": "818fa1f8e0eb99c8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       loss  accuracy  params_batch_size  params_epochs  params_learning_rate  \\\n",
       "0  1.242896      0.35                242            111              0.359445   \n",
       "1  3.605458      0.40                131            120              0.462883   \n",
       "2  0.850031      0.45                110            185              0.233160   \n",
       "3  1.584767      0.45                109            132              0.449575   \n",
       "4  2.270909      0.45                192            125              0.410574   \n",
       "5  2.904730      0.50                214            155              0.103348   \n",
       "6  1.997360      0.55                111            186              0.013113   \n",
       "\n",
       "   params_two_layers  params_units      time  trial_time     name  \n",
       "0               True            10  3.284449    3.284449  RNN_EBM  \n",
       "1              False            10  2.815903    2.815903  RNN_EBM  \n",
       "2               True            10  4.446019    4.446019  RNN_EBM  \n",
       "3               True             2  3.408573    3.408573  RNN_EBM  \n",
       "4              False             2  3.006101    3.006101  RNN_EBM  \n",
       "5               True             2  3.836699    3.836699  RNN_EBM  \n",
       "6              False             2  4.049156    4.049156  RNN_EBM  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>params_batch_size</th>\n",
       "      <th>params_epochs</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_two_layers</th>\n",
       "      <th>params_units</th>\n",
       "      <th>time</th>\n",
       "      <th>trial_time</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.242896</td>\n",
       "      <td>0.35</td>\n",
       "      <td>242</td>\n",
       "      <td>111</td>\n",
       "      <td>0.359445</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>3.284449</td>\n",
       "      <td>3.284449</td>\n",
       "      <td>RNN_EBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.605458</td>\n",
       "      <td>0.40</td>\n",
       "      <td>131</td>\n",
       "      <td>120</td>\n",
       "      <td>0.462883</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>2.815903</td>\n",
       "      <td>2.815903</td>\n",
       "      <td>RNN_EBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.850031</td>\n",
       "      <td>0.45</td>\n",
       "      <td>110</td>\n",
       "      <td>185</td>\n",
       "      <td>0.233160</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>4.446019</td>\n",
       "      <td>4.446019</td>\n",
       "      <td>RNN_EBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.584767</td>\n",
       "      <td>0.45</td>\n",
       "      <td>109</td>\n",
       "      <td>132</td>\n",
       "      <td>0.449575</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>3.408573</td>\n",
       "      <td>3.408573</td>\n",
       "      <td>RNN_EBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.270909</td>\n",
       "      <td>0.45</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>0.410574</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>3.006101</td>\n",
       "      <td>3.006101</td>\n",
       "      <td>RNN_EBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.904730</td>\n",
       "      <td>0.50</td>\n",
       "      <td>214</td>\n",
       "      <td>155</td>\n",
       "      <td>0.103348</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>3.836699</td>\n",
       "      <td>3.836699</td>\n",
       "      <td>RNN_EBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.997360</td>\n",
       "      <td>0.55</td>\n",
       "      <td>111</td>\n",
       "      <td>186</td>\n",
       "      <td>0.013113</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>4.049156</td>\n",
       "      <td>4.049156</td>\n",
       "      <td>RNN_EBM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T09:14:50.691325Z",
     "start_time": "2025-06-18T09:14:50.680606Z"
    }
   },
   "cell_type": "code",
   "source": "mlp_tdidf_params",
   "id": "12a3d5df3f0ac25f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       loss  accuracy  params_epochs  params_learning_rate  params_units  \\\n",
       "0  0.683026      0.50            197              0.341752             5   \n",
       "1  0.687060      0.55            176              0.071278             3   \n",
       "2  0.690794      0.55            163              0.060066             6   \n",
       "3  0.703902      0.55            109              0.001009             3   \n",
       "4  0.676819      0.60            134              0.363623             4   \n",
       "5  0.689091      0.60            157              0.443271             5   \n",
       "6  0.704707      0.60            179              0.446684             3   \n",
       "\n",
       "       time  trial_time     name  \n",
       "0  0.698219    0.698219  MLP_BOW  \n",
       "1  0.660791    0.660791  MLP_BOW  \n",
       "2  0.644117    0.644117  MLP_BOW  \n",
       "3  0.537385    0.537385  MLP_BOW  \n",
       "4  0.566488    0.566488  MLP_BOW  \n",
       "5  0.609242    0.609242  MLP_BOW  \n",
       "6  0.659848    0.659848  MLP_BOW  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>params_epochs</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_units</th>\n",
       "      <th>time</th>\n",
       "      <th>trial_time</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.683026</td>\n",
       "      <td>0.50</td>\n",
       "      <td>197</td>\n",
       "      <td>0.341752</td>\n",
       "      <td>5</td>\n",
       "      <td>0.698219</td>\n",
       "      <td>0.698219</td>\n",
       "      <td>MLP_BOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.687060</td>\n",
       "      <td>0.55</td>\n",
       "      <td>176</td>\n",
       "      <td>0.071278</td>\n",
       "      <td>3</td>\n",
       "      <td>0.660791</td>\n",
       "      <td>0.660791</td>\n",
       "      <td>MLP_BOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.690794</td>\n",
       "      <td>0.55</td>\n",
       "      <td>163</td>\n",
       "      <td>0.060066</td>\n",
       "      <td>6</td>\n",
       "      <td>0.644117</td>\n",
       "      <td>0.644117</td>\n",
       "      <td>MLP_BOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.703902</td>\n",
       "      <td>0.55</td>\n",
       "      <td>109</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>3</td>\n",
       "      <td>0.537385</td>\n",
       "      <td>0.537385</td>\n",
       "      <td>MLP_BOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.676819</td>\n",
       "      <td>0.60</td>\n",
       "      <td>134</td>\n",
       "      <td>0.363623</td>\n",
       "      <td>4</td>\n",
       "      <td>0.566488</td>\n",
       "      <td>0.566488</td>\n",
       "      <td>MLP_BOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.689091</td>\n",
       "      <td>0.60</td>\n",
       "      <td>157</td>\n",
       "      <td>0.443271</td>\n",
       "      <td>5</td>\n",
       "      <td>0.609242</td>\n",
       "      <td>0.609242</td>\n",
       "      <td>MLP_BOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.704707</td>\n",
       "      <td>0.60</td>\n",
       "      <td>179</td>\n",
       "      <td>0.446684</td>\n",
       "      <td>3</td>\n",
       "      <td>0.659848</td>\n",
       "      <td>0.659848</td>\n",
       "      <td>MLP_BOW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T09:17:25.701414Z",
     "start_time": "2025-06-18T09:17:25.688334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all = tb.All_trials_table()\n",
    "all.add_record(mlp_tdidf_params)\n",
    "all.add_record(rnn_emb_params)\n",
    "all.show(tabulate_view=False)"
   ],
   "id": "dc9e07c391b1be66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding a new record with params.\n",
      "Adding a new record with params.\n",
      "\n",
      "Table info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14 entries, 0 to 13\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   loss                  14 non-null     float64\n",
      " 1   accuracy              14 non-null     float64\n",
      " 2   params_epochs         14 non-null     object \n",
      " 3   params_learning_rate  14 non-null     float64\n",
      " 4   params_units          14 non-null     object \n",
      " 5   time                  14 non-null     float64\n",
      " 6   trial_time            14 non-null     float64\n",
      " 7   name                  14 non-null     object \n",
      " 8   params_batch_size     7 non-null      float64\n",
      " 9   params_two_layers     7 non-null      object \n",
      "dtypes: float64(6), object(4)\n",
      "memory usage: 1.2+ KB\n",
      "\n",
      "Records preview:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python_files\\DL_final2\\source\\table.py:121: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.df =pd.concat([self.df, df], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        loss  accuracy params_epochs  params_learning_rate params_units  \\\n",
       "0   0.683026      0.50           197              0.341752            5   \n",
       "1   0.687060      0.55           176              0.071278            3   \n",
       "2   0.690794      0.55           163              0.060066            6   \n",
       "3   0.703902      0.55           109              0.001009            3   \n",
       "4   0.676819      0.60           134              0.363623            4   \n",
       "5   0.689091      0.60           157              0.443271            5   \n",
       "6   0.704707      0.60           179              0.446684            3   \n",
       "7   1.242896      0.35           111              0.359445           10   \n",
       "8   3.605458      0.40           120              0.462883           10   \n",
       "9   0.850031      0.45           185              0.233160           10   \n",
       "10  1.584767      0.45           132              0.449575            2   \n",
       "11  2.270909      0.45           125              0.410574            2   \n",
       "12  2.904730      0.50           155              0.103348            2   \n",
       "13  1.997360      0.55           186              0.013113            2   \n",
       "\n",
       "        time  trial_time     name  params_batch_size params_two_layers  \n",
       "0   0.698219    0.698219  MLP_BOW                NaN               NaN  \n",
       "1   0.660791    0.660791  MLP_BOW                NaN               NaN  \n",
       "2   0.644117    0.644117  MLP_BOW                NaN               NaN  \n",
       "3   0.537385    0.537385  MLP_BOW                NaN               NaN  \n",
       "4   0.566488    0.566488  MLP_BOW                NaN               NaN  \n",
       "5   0.609242    0.609242  MLP_BOW                NaN               NaN  \n",
       "6   0.659848    0.659848  MLP_BOW                NaN               NaN  \n",
       "7   3.284449    3.284449  RNN_EBM              242.0              True  \n",
       "8   2.815903    2.815903  RNN_EBM              131.0             False  \n",
       "9   4.446019    4.446019  RNN_EBM              110.0              True  \n",
       "10  3.408573    3.408573  RNN_EBM              109.0              True  \n",
       "11  3.006101    3.006101  RNN_EBM              192.0             False  \n",
       "12  3.836699    3.836699  RNN_EBM              214.0              True  \n",
       "13  4.049156    4.049156  RNN_EBM              111.0             False  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>params_epochs</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_units</th>\n",
       "      <th>time</th>\n",
       "      <th>trial_time</th>\n",
       "      <th>name</th>\n",
       "      <th>params_batch_size</th>\n",
       "      <th>params_two_layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.683026</td>\n",
       "      <td>0.50</td>\n",
       "      <td>197</td>\n",
       "      <td>0.341752</td>\n",
       "      <td>5</td>\n",
       "      <td>0.698219</td>\n",
       "      <td>0.698219</td>\n",
       "      <td>MLP_BOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.687060</td>\n",
       "      <td>0.55</td>\n",
       "      <td>176</td>\n",
       "      <td>0.071278</td>\n",
       "      <td>3</td>\n",
       "      <td>0.660791</td>\n",
       "      <td>0.660791</td>\n",
       "      <td>MLP_BOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.690794</td>\n",
       "      <td>0.55</td>\n",
       "      <td>163</td>\n",
       "      <td>0.060066</td>\n",
       "      <td>6</td>\n",
       "      <td>0.644117</td>\n",
       "      <td>0.644117</td>\n",
       "      <td>MLP_BOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.703902</td>\n",
       "      <td>0.55</td>\n",
       "      <td>109</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>3</td>\n",
       "      <td>0.537385</td>\n",
       "      <td>0.537385</td>\n",
       "      <td>MLP_BOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.676819</td>\n",
       "      <td>0.60</td>\n",
       "      <td>134</td>\n",
       "      <td>0.363623</td>\n",
       "      <td>4</td>\n",
       "      <td>0.566488</td>\n",
       "      <td>0.566488</td>\n",
       "      <td>MLP_BOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.689091</td>\n",
       "      <td>0.60</td>\n",
       "      <td>157</td>\n",
       "      <td>0.443271</td>\n",
       "      <td>5</td>\n",
       "      <td>0.609242</td>\n",
       "      <td>0.609242</td>\n",
       "      <td>MLP_BOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.704707</td>\n",
       "      <td>0.60</td>\n",
       "      <td>179</td>\n",
       "      <td>0.446684</td>\n",
       "      <td>3</td>\n",
       "      <td>0.659848</td>\n",
       "      <td>0.659848</td>\n",
       "      <td>MLP_BOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.242896</td>\n",
       "      <td>0.35</td>\n",
       "      <td>111</td>\n",
       "      <td>0.359445</td>\n",
       "      <td>10</td>\n",
       "      <td>3.284449</td>\n",
       "      <td>3.284449</td>\n",
       "      <td>RNN_EBM</td>\n",
       "      <td>242.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.605458</td>\n",
       "      <td>0.40</td>\n",
       "      <td>120</td>\n",
       "      <td>0.462883</td>\n",
       "      <td>10</td>\n",
       "      <td>2.815903</td>\n",
       "      <td>2.815903</td>\n",
       "      <td>RNN_EBM</td>\n",
       "      <td>131.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.850031</td>\n",
       "      <td>0.45</td>\n",
       "      <td>185</td>\n",
       "      <td>0.233160</td>\n",
       "      <td>10</td>\n",
       "      <td>4.446019</td>\n",
       "      <td>4.446019</td>\n",
       "      <td>RNN_EBM</td>\n",
       "      <td>110.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.584767</td>\n",
       "      <td>0.45</td>\n",
       "      <td>132</td>\n",
       "      <td>0.449575</td>\n",
       "      <td>2</td>\n",
       "      <td>3.408573</td>\n",
       "      <td>3.408573</td>\n",
       "      <td>RNN_EBM</td>\n",
       "      <td>109.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.270909</td>\n",
       "      <td>0.45</td>\n",
       "      <td>125</td>\n",
       "      <td>0.410574</td>\n",
       "      <td>2</td>\n",
       "      <td>3.006101</td>\n",
       "      <td>3.006101</td>\n",
       "      <td>RNN_EBM</td>\n",
       "      <td>192.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.904730</td>\n",
       "      <td>0.50</td>\n",
       "      <td>155</td>\n",
       "      <td>0.103348</td>\n",
       "      <td>2</td>\n",
       "      <td>3.836699</td>\n",
       "      <td>3.836699</td>\n",
       "      <td>RNN_EBM</td>\n",
       "      <td>214.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.997360</td>\n",
       "      <td>0.55</td>\n",
       "      <td>186</td>\n",
       "      <td>0.013113</td>\n",
       "      <td>2</td>\n",
       "      <td>4.049156</td>\n",
       "      <td>4.049156</td>\n",
       "      <td>RNN_EBM</td>\n",
       "      <td>111.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T09:17:22.848828Z",
     "start_time": "2025-06-18T09:17:22.838313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reload(prd)\n",
    "reload(dat)\n",
    "reload(mlp)\n",
    "reload(tb)\n",
    "reload(comp)\n",
    "reload(rnn)"
   ],
   "id": "38553e88d8187c3e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'source.recurent_neural_networks' from 'C:\\\\Python_files\\\\DL_final2\\\\source\\\\recurent_neural_networks.py'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T09:17:29.539705Z",
     "start_time": "2025-06-18T09:17:29.436684Z"
    }
   },
   "cell_type": "code",
   "source": "all.plot_time_complexity()",
   "id": "d300226bf8bf8d1e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAHqCAYAAAAZLi26AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWVlJREFUeJzt3QmczfX+x/HPDMNgzAgxlHARxr4kFCFbiZR/VLLltohkydZia7GkKFubrVxXyVJaBslSlkTJGpGQbSrL2IYxc/6Pz9c9p3NmM8v5zTm/Oa/n43EeM+f7+51zvud856j377sFORwOhwAAAAAAAK8L9v5TAgAAAAAARegGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYA+KXu3btLmTJlfF2NHEU/T/1crTJ79mwJCgqS33//Xay0evVq8zqffPKJ5ET6+en7088zs5+N/gQA+AdCNwAg22gYSM/NnwPDiRMn5Nlnn5VKlSpJ/vz5pUCBAlKnTh15+eWX5fTp076unt+ZNm1apsKjPxg5cqT5ewwODpbDhw8nOx4bGyv58uUz5/Tp08cndQQA+L/cvq4AACBwfPjhhx73P/jgA1mxYkWy8sqVK8t7770niYmJ4k9++OEHufvuu+XcuXPyyCOPmLCtNm/eLGPHjpW1a9fK8uXLJVB16dJFHnzwQcmbN69H6C5atKilPexW0/fz3//+VwYPHuxRvmjRIp/VCQBgH4RuAEC20aDqbuPGjSZ0Jy33R9qLfd9990muXLnkp59+Mj3d7l555RVzoSCQ6Wejt5xGL7SkFLrnzZsnbdq0kYULF/qsbgAA/8fwcgCALeZ0O+e5TpgwQaZOnSr/+te/zPDuli1bmqG/DodDXnrpJbnxxhvNkN97771XTp48mex5v/rqK2nUqJEZFl6wYEETmnbu3HnN+rzzzjty5MgReeONN5IFblW8eHF54YUXPMq0l7dKlSqmp7RkyZLSu3fvZEPQmzRpIlWrVpVt27bJHXfcYd5T+fLlXfOV16xZI7feeqt5TxUrVpSvv/46xSHQv/zyi3Ts2FHCw8OlSJEi8swzz0hcXNw135fWp1+/flKqVClTT33tcePGuUYZ6OfatGlTuf766yUmJsb1uMuXL0u1atWkXLlycv78+RTndGv76Wer78E5dUDf72+//WZ+nzhxYrL6rF+/3hzTkHstCQkJ8txzz0lkZKRpz3bt2nkMAx8xYoSEhITIn3/+meyxjz/+uBQqVChdn9HDDz8sW7duNZ+x0/Hjx+Wbb74xx1Kin1XPnj3N30VoaKjUqFFD5syZk+Lnr3/rERERpj7dunVLdZqCvv7//d//SeHChc1z1q1bVz777LNr1h8A4FuEbgCArfznP/8xYfbpp5+WgQMHmkCnYVMDb3R0tAwZMsQEqqVLl5q51+50GLuG7LCwMBMsX3zxRdm1a5fcfvvt11z8S8ONBl8NPemhYVhDtobt119/XTp06GCCu14kiI+P9zj31KlTcs8995hwPX78eBN+dZj2Rx99ZH5qT6sOX9dwq69/9uzZZK+nn4EGyDFjxpjz33rrLfM5pOXChQsm6M+dO1e6du1qHnPbbbfJsGHDZMCAAeYcDcAzZ840z/3kk096BFoN1LNmzTKBNyWTJk0yF0H0IoV+9np7/vnnzQUTfR1ty6S0TC+G6EWTa9HRBV988YVp8759+5pRE82bN5eLFy+6hrtfuXLFfI7u9IKBXtTQNtHwei2NGzc270N7tp30OfXvSP+ektLX14sL+n47d+4sr732mgnVGq7ffPNN13l6QUPfp56noz10XYA//vjDBO+k9LOuX7++7N69W4YOHWr+pvRzb9++vSxevPia7wEA4EMOAAB8pHfv3o7U/lPUrVs3R+nSpV33Dxw4YM69/vrrHadPn3aVDxs2zJTXqFHDER8f7yp/6KGHHHny5HHExcWZ+2fPnnUUKlTI8dhjj3m8zvHjxx0RERHJypO67rrrzGukR0xMjHntli1bOhISElzlU6ZMMXWdOXOmq+yOO+4wZfPmzXOV/fLLL6YsODjYsXHjRlf5smXLTPmsWbNcZSNGjDBl7dq186jDU089Zcp//vlnV5l+nvq5Or300kuOAgUKOPbu3evx2KFDhzpy5crlOHTokKvsnXfeMc83d+5cUyc93q9fP4/Hab30HG0rpypVqpj3mJTz+Xbv3u0qu3z5sqNo0aIedUzJqlWrzGNvuOEGR2xsrKv8448/NuVvvvmmq6xBgwaOW2+91ePxixYtMufp86TF+dn++eefjmeffdZRvnx517FbbrnF0aNHD/O7nqN/y06TJk1yfVbu703rEhYW5qrzkiVLzHnjx493nXflyhVHo0aNkrXznXfe6ahWrZrr71klJiY6GjZs6KhQoUKyz+Za7w0AkH3o6QYA2MoDDzxgeg2dtHdYaU9h7ty5Pcq1R1OHhCvtBdVhuw899JD89ddfrpvOQdZzV61alebr6krV2gObHjoEXF9bh23rytdOjz32mBn+rb2z7rTHVHu0nXQYuQ411gXlnO/P/b3q8OyktFfdnY4EUF9++WWq9VywYIEZan/dddd5fCbaW6xDt3VhOCftNW/VqpV5Xu1B1mHlr776qmSW9sxrL7N7b/eyZcvM66d3jr/2zru3iY4CKFGihMd71nO+//572b9/v6tMX1OH02svf3rpMPJ9+/aZxfScP1MbWq6vr0Pe9W/NSYe5a2+8LsKnozOc5+nfbK9evVzn6d+js+2cdJqEDmXXz0xHOTjb6e+//zZt8uuvv7r+zgEA/oeF1AAAtnLTTTd53HcGcA1RKZXr0G2lwUQ1a9YsxefVMJwWPZ7SsO6UHDx40BWe3eXJk8cMrXYed9KhyzqMO2n9r/We3FWoUMHjvoZiDfxpDZvXz0Tnkut87ZS4z+FWM2bMMM+rj9O51zrcPrP0okLbtm3NkG2di+8MwzfccEOqbXSt96yfoc5Jd3/PnTp1Mhc/9LmHDx8uZ86ckc8//1z69++f7DNPS61atcwwea2v1l1DdWr11PbVurlfcFF6EcV53PlTLxLoRRd3Sf9uNORrh7pOh9Bbam2lnx0AwP8QugEAtpLa6tiplV8d/SuuhcF0/qwGpqTce8lTooFLF9PSHmwNz/7wntKSnkCpn0mLFi2SrcrtdPPNN3vc1/3TL126ZH7fvn27NGjQQLJCe6G1t10DvC7KpvPmn3rqqWRhNSu0F1/nyztDt87l1veQmRXztWd7+vTppnddw7w365kW59+urlGgPdsp0YsNAAD/ROgGAAQE7aFVxYoVM8OnM0p7ZTds2GC2h3IfNpyS0qVLm5979uwxPdtOGtgPHDiQqde/Fu19Llu2rEfvqIY19xXgU/pMdLhzeupz7NgxM+xZF4LTiw7OAOh8r5kJ/61btza97BqIdei8LuymQ9fTyzl6wf1ihL7v6tWrJwv3umCZDgnX19Jea11VPjOhW4O7fhZJ95Z3p5+JjiDQz989mDtXP3d+Zvpz5cqVpg3ce7v178ad829Ih6hb8bcDALAWc7oBAAFBA6IOEdd5yElXD1cpbSvlTlfu1qHAumL63r17Uxzeq6tPKw1GGkx1NXD3Xmkdnq3Dm1Na8TqrdBs1d5MnTzY/77rrrlQfo3OE9UKCzqVOSue/68rf7vPRNUTqe3j33XfNyADdEutave66wnZqW2Dpc+gFjI8//thsN6a93UkDc1o++OADjyH/2outgTjpe9b7RYsWNSvW63zqzO4LrxcpdEV2XSG+Xr16qZ6nq8frlmLuq6brZ6ltouHaOZdcz9Ny7T130rn0zrZz0gtFuhq6rn6v7y+jf7sAAN+ipxsAEBA0cGu40Z7U2rVrm4XLtJf10KFDZmEz3cJqypQpaQ5T1q2ZNCjVrFnTBLc6deqYYz/++KPZV9o53FqfV7fdGjVqlOnN1f2jtfdStzq75ZZbMh360qI96Po6+noapHUbMO2Z1f2hUzNo0CAzpFuHX+t2Vvp+dFsyHTquAVbnRmtY1W3B9DPSYKzzz5UGQ30f+pnqkPDU6HPqOXpBQodAa4B0nwvt3KpMF7LTUJwRul+1bvfWo0cPOXHihAnE+hp6gcCd9hBre2v76pD9a41USIvuf34tuuicBmT9TLds2WJGG+jnuW7dOlNH5+JvOnpC/+50CzD9rKOiomTRokXmwkxKF1X0veqFCX1/2vut71nbWrcZ+/nnnzP9ngAA1iJ0AwAChoZQ3Tdb97zWvZN1bq8uPqUreGtwuxYdAr1jxw7zWA2hOsRYhw/rAlkanPr06eOxT7eGbw16umiXBkQNY9rTriHQ27RXVYc+az20B1nrovVMS/78+U3Pr9ZJ51Zrz7FenNC53HrBQBdu00Cn9deA6L5/tO4/rUPtdT649iS7D213p3XSBcN0/3HtldZeXvfQraFch3rr/tP6nBnx3HPPmWHc2vOsz33nnXeaCxv6vpLScK9toefoiAUr6QJzOv9d22LOnDlm5XtdHE0vXmgQd9K/Hb3ooQu96UUSHYqvF050D24dAu9OA/nmzZtNu+jFD125XC9g6Hn6GQMA/FeQ7hvm60oAAIDM0XCvQUyHGGuvtB1pcNSLEjq/2SraE6wjFPTCQkbmjQMAkFXM6QYAAD6jvbe6Krz2RFvpvffeM/Op77//fktfBwCApBheDgAAsp0O09f5zjqUWod76xZcVli6dKns2rXLLP6mQ+51YTcAALIToRsAAGQ7XVhs9OjRZq6zLkIXGhpqyevoNme64JgugKfD8AEAyG7M6QYAAAAAwCLM6QYAAAAAwCKEbgAAAAAALMKcbhFJTEyUo0ePSsGCBc0emQAAAAAApEVnap89e1ZKliwpwcGp92cTukVM4C5VqpSvqwEAAAAAsJnDhw/LjTfemOpxQreI6eF2fljh4eE+qUN8fLwsX75cWrZsKSEhIT6pA9KHtrIH2skeaCf7oK3sgXayB9rJPmgre4j3UTvFxsaazltnnvTL0D1mzBhZtGiR/PLLL5IvXz5p2LChjBs3zmwf4hQXFycDBw6U+fPny6VLl6RVq1Yybdo0KV68uOucQ4cOSa9evWTVqlUSFhYm3bp1M8+dO3f63p5zSLkGbl+G7vz585vX5wvt32gre6Cd7IF2sg/ayh5oJ3ugneyDtrKHeB+307WmKPt0IbU1a9ZI7969ZePGjbJixQrzYenVifPnz7vO6d+/vyxdulQWLFhgzteh4Pfff7/reEJCgrRp00YuX74s69evlzlz5sjs2bNl+PDhPnpXAAAAAAD4QU93dHS0x30Ny8WKFZMtW7ZI48aN5cyZMzJjxgyZN2+eNGvWzJwza9YsqVy5sgnq9evXN8MIdu3aJV9//bXp/a5Zs6a89NJLMmTIEBk5cqTkyZPHR+8OAAAAABDo/GpOt4ZsVbhwYfNTw7f2fjdv3tx1TqVKleSmm26SDRs2mNCtP6tVq+Yx3FyHoOtw8507d0qtWrWSvY4OU9eb+1h8pa+lN19wvq6vXh/pR1vZA+1kD7STfdBW9kA72QPtZB+0lT3E+6id0vt6uf1p265+/frJbbfdJlWrVjVlx48fNz3VhQoV8jhXA7Yec57jHridx53HUqLzvUeNGpWsXHvNdS6AL+kwe9gDbWUPtJM90E72QVvZA+1kD7STfdBW9rAim9vpwoUL9grdOrd7x44d8t1331n+WsOGDZMBAwYkW3VO55P7ciE1/SNp0aIFizT4OdrKHmgne6Cd7IO2sgfayR5oJ/ugrewh3kft5BwxbYvQ3adPH/n8889l7dq1HvubRUZGmgXSTp8+7dHbfeLECXPMec6mTZs8nk+PO4+lJG/evOaWlDaQr79M/lAHpA9tZQ+0kz3QTvZBW9kD7WQPtJN90Fb2EJLN7ZTe1/Lp6uUOh8ME7sWLF8s333wjZcuW9Thep04d80ZWrlzpKtuzZ4/ZIqxBgwbmvv7cvn27xMTEuM7RqxzaYx0VFZWN7wYAAAAAAD/q6dYh5boy+aeffmo2FHfOwY6IiDD7duvPnj17mqHguriaBumnn37aBG1dRE3pkHAN1126dJHx48eb53jhhRfMc6fUmw0AAAAAQECE7unTp5ufTZo08SjXbcG6d+9ufp84caIEBwdLhw4dzIrjujL5tGnTXOfmypXLDE3X1co1jBcoUEC6desmo0ePzuZ3AwAAAACAH4VuHV5+LaGhoTJ16lRzS03p0qXlyy+/9HLtAAAAAADIGp/O6QYAAAAAICfzi9XLYR8JiQ7ZdOCkxJyNk2IFQ6Ve2cKSKzjI19UCAAAAAL9E6Ea6Re84JqOW7pJjZ+JcZSUiQmVE2yhpXbWET+sGAAAAAP6I4eVId+DuNfdHj8Ctjp+JM+V6HAAAAADgidCNdA0p1x7ulJa9c5bpcT0PAAAAAPAPQjeuSedwJ+3hdqdRW4/reQAAAACAfxC6cU26aJo3zwMAAACAQEHoxjXpKuXePA8AAAAAAgWhG9ek24LpKuWpbQym5XpczwMAAAAA/IPQjWvSfbh1WzCVNHg77+tx9usGAAAAAE+EbqSL7sM9/ZHaEhnhOYRc72s5+3QDAAAAQHK5UygDUqTBukVUpFmlXBdN0zncOqScHm4AAAAASBmhGxmiAbtBuSK+rgYAAAAA2ALDywEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACL5LbqiQEAAAAgx0tMEDm4XuTcCZGw4iKlG4oE5/J1reBHCN0AAAAAkBm7PhOJHiISe/SfsvCSIq3HiUS182XN4EcYXg4AAAAAmQncH3f1DNwq9tjVcj0OELoBAAAAIBNDyrWHWxwpHPxfWfTQq+ch4BG6AQAAACAjdA530h5uDw6R2CNXz0PG6IWKA9+KbP/k6s8ccOGCOd0AAAAAkBG6aJo3z0OOniNPTzcAAAAAZISuUu7N8yA5eY48oRsAAAAAMkK3BdMeWAlK5YQgkfAbrp4HCfQ58oRuAAAAAMgI3YdbhzwbSYP3/+63Hst+3el1MGfPkSd0AwAAAEBG6Rzjjh+IhJfwLNcecC238RzkbHcuZ8+RZyE1AAAAAMgMDdaV2lztgdVAqHO4dUg5PdwZE5az58gTugEAAAAgszRgl23k61rkjDnyscdSmdetc+RL2naOPMPLAQAAAAC+E5yz58gTugEAAAAAvhWVc+fIM7wcAAAAAOB7UTlzjjyhGwAAAADgH4Jz3hx5hpcDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAkBND99q1a6Vt27ZSsmRJCQoKkiVLlngcP3funPTp00duvPFGyZcvn0RFRcnbb7/tcU5cXJz07t1bihQpImFhYdKhQwc5ceJENr8TAAAAAAD8LHSfP39eatSoIVOnTk3x+IABAyQ6Olrmzp0ru3fvln79+pkQ/tlnn7nO6d+/vyxdulQWLFgga9askaNHj8r999+fje8CAAAAAICU5RYfuuuuu8wtNevXr5du3bpJkyZNzP3HH39c3nnnHdm0aZO0a9dOzpw5IzNmzJB58+ZJs2bNzDmzZs2SypUry8aNG6V+/frZ9l4AAAAAALDVnO6GDRuaXu0jR46Iw+GQVatWyd69e6Vly5bm+JYtWyQ+Pl6aN2/uekylSpXkpptukg0bNviw5gAAAAAA+Lin+1omT55serd1Tnfu3LklODhY3nvvPWncuLE5fvz4ccmTJ48UKlTI43HFixc3x1Jz6dIlc3OKjY01PzXA680XnK/rq9dXCYkO2XLwlPx17pIUDcsrdUpfJ7mCg3xWH3/lD22Fa6Od7IF2sg/ayh5oJ3ugneyDtrKHeB+1U3pfz+9Dtw4T197u0qVLm4XXdNE0XXjNvXc7o8aMGSOjRo1KVr58+XLJnz+/+NKKFSvEH/wlIst2+7oW/s1f2gppo53sgXayD9rKHmgne6Cd7IO2socV2dxOFy5csHfovnjxojz33HOyePFiadOmjSmrXr26bN26VSZMmGBCd2RkpFy+fFlOnz7t0dutq5frsdQMGzbMLNLm3tNdqlQpM2w9PDxcfEGvkugfSYsWLSQkJCRbX/vr3Sek/0dbxZGk3NnHPbFTTWleuXi21smf+bKtkH60kz3QTvZBW9kD7WQPtJN90Fb2EO+jdnKOmLZt6HYO9dYh5e5y5coliYmJ5vc6deqYD3XlypVmqzC1Z88eOXTokDRo0CDV586bN6+5JaXP5esvU3bXQYeUj/5ij8QlpDyMXEv1eMuqNzDU3A//XnBttJM90E72QVvZA+1kD7STfdBW9hCSze2U3tfyaejWfbj37dvnun/gwAHTk124cGGzGNodd9whgwYNMnt06/By3RLsgw8+kDfeeMOcHxERIT179jS91voY7aV++umnTeBm5fL02XTgpBw7E5fqce391uN6XoNyRbK1bgAAAABgdz4N3Zs3b5amTZu67juHfOs2YbNnz5b58+eboeCdO3eWkydPmuD9yiuvyJNPPul6zMSJE01vuPZ06+JorVq1kmnTpvnk/dhRzNk4r54HAAAAAPCT0K37b+tWYKnRedm673ZaQkNDZerUqeaGjCtWMNSr5wEAAAAAbLJPN6xXr2xhKRER6lo0LSkt1+N6HgAAAAAgYwjdAU4XRxvRNsr8njR4O+/rcRZRAwAAAICMI3RDWlctIdMfqS2REZ5DyPW+lutxAAAAAEDG+e2WYcheGqxbREWaVcp10TSdw61DyunhBgAAAIDMI3TDRQM224IBAAAAgPcQuuEhIdFBbzcAAAAAeAmhGy7RO47JqKW75NiZf/bk1pXLdSE15nUDAAAAQMaxkBpcgbvX3B89Arc6fibOlOtxAAAAAEDGELphhpRrD7cjhWPOMj2u5wEAAAAA0o/QDTOHO2kPtzuN2npczwMAAAAApB+hG2bRNG+eBwAAAAC4itANs0q5N88DAAAAAFxF6IbZFkxXKU9tYzAt1+N6HgAAAAAg/QjdMPtw67ZgKmnwdt7X4+zXDQAAAAAZQ+iGoftwT3+ktkRGeA4h1/tazj7dAAAAAJBxuTPxGORQGqxbREWaVcp10TSdw61DyunhBgAAAIDMIXTDgwbsBuWK+LoaAAAAAJAjMLwcAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAH8J3XPmzJEvvvjCdX/w4MFSqFAhadiwoRw8eNDb9QMAAAAAIHBC96uvvir58uUzv2/YsEGmTp0q48ePl6JFi0r//v2tqCMAAAAAALaUO6MPOHz4sJQvX978vmTJEunQoYM8/vjjctttt0mTJk2sqCMAAAAAAIHR0x0WFiZ///23+X358uXSokUL83toaKhcvHjR+zUEAAAAACBQero1ZP/73/+WWrVqyd69e+Xuu+825Tt37pQyZcpYUUcAAAAAAAKjp1vncDdo0ED+/PNPWbhwoRQpUsSUb9myRR566CEr6ggAAAAAQGD0dOtK5VOmTElWPmrUKG/VCQAAAACAwAzd6vTp07Jp0yaJiYmRxMREV3lQUJB06dLFm/UDAAAAACBwQvfSpUulc+fOcu7cOQkPDzdB24nQDQAAAABAFuZ0Dxw4UB599FETurXH+9SpU67byZMnM/p0AAAAAADkWBkO3UeOHJG+fftK/vz5rakRAAAAAACBGrpbtWolmzdvtqY2AAAAAAAE2pzuzz77zPV7mzZtZNCgQbJr1y6pVq2ahISEeJzbrl0779cSAAAAAICcGrrbt2+frGz06NHJynQhtYSEBO/UDAAAAACAQAjd7tuCAQAAAAAAi+Z0AwAAAAAAi0K3rlz+1ltvJSufMmWK9OvXL6NPBx9LSHTIhv1/y6dbj5ifeh8AAAAAkI3Dy90tXLjQY2E1p4YNG8rYsWNl0qRJXqoarBa945iMWrpLjp2Jc5WViAiVEW2jpHXVEj6tGwAAAAAEZE/333//LREREcnKw8PD5a+//vJWvZANgbvX3B89Arc6fibOlOtxAAAAAEA2h+7y5ctLdHR0svKvvvpK/vWvf2WxOsgOOoRce7hTGkjuLNPjDDUHAAAAgGweXj5gwADp06eP/Pnnn9KsWTNTtnLlSnn99dcZWm4Tmw6cTNbD7U6jth7X8xqUK5KtdQMAAACAgA7djz76qFy6dEleeeUVeemll0xZmTJlZPr06dK1a1cr6ggvizkb59XzAAAAAABeCt2qV69e5qa93fny5ZOwsLDMPA18pFjBUK+eBwAAAADw8j7dGrj37NkjW7duZQE1m6lXtrBZpTwoleNarsf1PAAAAABANobu8+fPmyHmJUqUkMaNG5ub/t6zZ0+5cOFCFqqC7JIrOMhsC6aSBm/nfT2u5wEAAAAAsjF060Jqa9askaVLl8rp06fN7dNPPzVlAwcOzEJVkJ10H+7pj9SWyAjPIeR6X8vZpxsAAAAAfDCne+HChfLJJ59IkyZNXGV33323mdvdsWNHs6Aa7EGDdYuoSLNKuS6apnO4dUg5PdwAAAAA4KPQrUPIixcvnqy8WLFiDC+3IQ3YbAsGAAAAAH4yvLxBgwYyYsQIiYv7ZzupixcvyqhRo8wxAAAAAACQydD95ptvyrp16+TGG2+UO++809xKlSol69evN8cyYu3atdK2bVspWbKkBAUFyZIlS5Kds3v3bmnXrp1ERERIgQIF5JZbbpFDhw65jmv47927txQpUsRsXdahQwc5ceJERt8WAAAAAAC+D91Vq1aVX3/9VcaMGSM1a9Y0t7Fjx5qyKlWqZHgl9Bo1asjUqVNTPL5//365/fbbpVKlSrJ69WrZtm2bvPjiixIa+s/iX/379zeLui1YsMAs5nb06FG5//77M/q2AAAAAADw/ZxulT9/fnnsscey/OJ33XWXuaXm+eefN4u0jR8/3lVWrlw51+9nzpyRGTNmyLx586RZs2ambNasWVK5cmXZuHGj1K9fP8t1BAAAAAAgW0P3nj17ZPLkyWbot9KQ26dPH9Mj7S2JiYnyxRdfyODBg6VVq1by008/SdmyZWXYsGHSvn17c86WLVskPj5emjdv7nqc1uGmm26SDRs2pBq6L126ZG5OsbGx5qc+l958wfm6vnp9pB9tZQ+0kz3QTvZBW9kD7WQPtJN90Fb2EO+jdkrv6wU5HA5HRrcMe/DBB6Vu3bquhdO0V/mHH36Q+fPnmznVmaFzuhcvXuwK1MePH5cSJUqYXvWXX35ZmjZtKtHR0fLcc8/JqlWr5I477jA93D169PAI0KpevXrm/HHjxqX4WiNHjjQLvyWlz6evBwAAAABAWnT3rocfftiMwA4PD/deT7f2PGtv8+jRoz3KdUVzPZbZ0J1ST7e69957zbxtpfPHdcG2t99+24TuzNL6DxgwwKOnWxeDa9myZZofltVXSVasWCEtWrSQkJAQn9QB6UNb2QPtZA+0k33QVvZAO9kD7WQftJU9+KqdnCOmryXDofvYsWPStWvXZOWPPPKIvPbaa+ItRYsWldy5c0tUVJRHuQ5l/+6778zvkZGRcvnyZTl9+rQUKlTIdY6uXq7HUpM3b15zS0obyNdfJn+oA9KHtrIH2skeaCf7oK3sgXayB9rJPmgrewjJ5nZK72tlePXyJk2ayLfffpusXINwo0aNxFvy5MljtgfT+ePu9u7dK6VLlza/16lTx7zRlStXuo7r+bqlGHuGAwAAAAB8LcM93bpn9pAhQ8wiZs6FynROt27ZpfOkP/vsM49z03Lu3DnZt2+f6/6BAwdk69atUrhwYbMY2qBBg6RTp07SuHFj15xu3R5Mtw9Tund3z549zVBxfYwODX/66adN4GblcgAAAACA7UL3U089ZX5OmzbN3FI65lwYLSEhIc3n2rx5swnTTs551t26dZPZs2fLfffdZ+Zv657gffv2lYoVK5qF3HTvbqeJEydKcHCwmUuuC6rpSudJ6wUAAAAAgC1Ct3OBM2/QoerXWjz90UcfNbfUhIaGytSpU80NAAAAAAB/kuE53QAAAAAAwMuh++677zb7jzmNHTvWrBru9PfffydbaRz+ISHRIRv2/y2fbj1ifup9AAAAAIAfDS9ftmyZmTPt9Oqrr0rHjh1dW3VduXIl2Urj8L3oHcdk1NJdcuxMnKusRESojGgbJa2rlvBp3QAAAAAgp0t3T3fSudfXmosN/wjcveb+6BG41fEzcaZcjwMAAAAArMOc7hxKh5BrD3dKl0acZXqcoeYAAAAA4AehW7cA01vSMvinTQdOJuvhdqdRW4/reQAAAAAAH8/p1uHk3bt3l7x585r7cXFx8uSTT0qBAgXMfff53vC9mLNxXj0PAAAAAGBh6O7WrZvH/UceeSTZOV27ds1EFWCFYgVDvXoeAAAAAMDC0D1r1qxMPD18pV7ZwmaVcl00LaVZ2zoxIDIi1JwHAAAAALAGC6nlULmCg8y2YCrpzHvnfT2u5wEAAAB+ITFB5MC3Its/ufpT7wOB0tMN+9F9uKc/UjvZPt3aw80+3QAAAPAruz4TiR4iEnv0n7LwkiKtx4lEtfNlzYAsIXTncBqsW0RFmlXKddE0ncOtQ8rp4QYAAIBfBe6PdX2oJBMjY49dLe/4AcEbtkXoDgAasBuUK+LragAAAADJ6RBy7eFOcSUiLQsSiR4qUqmNSHAuH1QQyIY53bVr15ZTp06Z30ePHi0XLlzI4ssCAAAAgIgcXO85pDwZh0jskavnATk1dO/evVvOnz9vfh81apScO3fO6noBAAAACATnTnj3PMCOw8tr1qwpPXr0kNtvv10cDodMmDBBwsLCUjx3+PDh3q4jAAAAgJwqrLh3zwPsGLpnz54tI0aMkM8//1yCgoLkq6++kty5kz9UjxG6AQAAAKRb6YZXVynXRdNSnNcddPW4ngfk1NBdsWJFmT9/vvk9ODhYVq5cKcWKFbO6bgAAAAByOl0cTbcFM6uXByUJ3v/bcaf1WBZRQ86e0+0uMTGRwA0AAADAe3Q7MN0WLLyEZ7n2cLNdGAJxy7D9+/fLpEmTzAJrKioqSp555hkpV66ct+sHAAAAIBBosNZtwXSVcl00Tedw65ByergRaD3dy5YtMyF706ZNUr16dXP7/vvvpUqVKrJixQpragkAAAAg59OAXbaRSLX/u/qTwI1A7OkeOnSo9O/fX8aOHZusfMiQIdKiRQtv1g8AAAAAgMDp6dYh5T179kxW/uijj8quXbu8VS8AAAAAAAIvdF9//fWydevWZOVaxgJrAAAAAABkYXj5Y489Jo8//rj89ttv0rDh1b3y1q1bJ+PGjZMBAwZk9OkAAAAAAMixMhy6X3zxRSlYsKC8/vrrMmzYMFNWsmRJGTlypPTt29eKOgIAAAAAEBihOygoyCykprezZ8+aMg3hAAAAAADAC/t0OxG2AQAAAADw4kJqAAAAAAAgfQjdAAAAAABYhNANAAAAAIA/hO74+Hi588475ddff7WqPgAAAAAABGboDgkJkW3btllXGwAAAAAAAnl4+SOPPCIzZsywpjYAAAAAAATylmFXrlyRmTNnytdffy116tSRAgUKeBx/4403vFk/AAAAAAACJ3Tv2LFDateubX7fu3evx7GgoCDv1QwAAAAAgEAL3atWrbKmJgAAAAAA5DCZ3jJs3759smzZMrl48aK573A4vFkvAAAAAAACL3T//fffZtuwm2++We6++245duyYKe/Zs6cMHDjQijoCAAAAABAYobt///5m67BDhw5J/vz5XeWdOnWS6Ohob9cPAAAAAIDAmdO9fPlyM6z8xhtv9CivUKGCHDx40Jt1AwAAAAAgsHq6z58/79HD7XTy5EnJmzevt+oFAAAAAEDghe5GjRrJBx984LFNWGJioowfP16aNm3q7foBAAAAABA4w8s1XOtCaps3b5bLly/L4MGDZefOnaane926ddbUEgAAAACAQOjprlq1quzdu1duv/12uffee81w8/vvv19++uknKVeunDW1BAAAAAAgEHq6VUREhDz//PPerw0AAAAAAIEeuk+dOiUzZsyQ3bt3m/tRUVHSo0cPKVy4sLfrBwAAAABA4AwvX7t2rZQpU0beeustE771pr+XLVvWHAMAAAAAAJns6e7du7d06tRJpk+fLrly5TJlCQkJ8tRTT5lj27dvz+hTAgAAAACQI2W4p3vfvn0ycOBAV+BW+vuAAQPMMQAAAAAAkMnQXbt2bddcbndaVqNGjYw+HQAAAAAAgT28fNu2ba7f+/btK88884zp1a5fv74p27hxo0ydOlXGjh1rXU0BAAAAAMiJobtmzZoSFBQkDofDVTZ48OBk5z388MNmvjcAAAAAAEhn6D5w4ID1NQEAAAAAIBBDd+nSpa2vCQAAAAAAgb5lmDp69Kh89913EhMTI4mJiR7HdM43AAAAAADIROiePXu2PPHEE5InTx4pUqSImevtpL8TugEAAAAAyGTofvHFF2X48OEybNgwCQ7O8I5jAAAAAAAEjAyn5gsXLsiDDz5I4AYAAAAA4BoynJx79uwpCxYsyOjDAAAAAAAIOBkeXj5mzBi55557JDo6WqpVqyYhISEex9944w1v1g8AAAAAgMAK3cuWLZOKFSua+0kXUgMAAAAAAJkM3a+//rrMnDlTunfvntGHAgAAAAAQUDI8pztv3rxy2223WVMbAAAAAAACOXQ/88wzMnnyZGtqAwAAAABAIA8v37Rpk3zzzTfy+eefS5UqVZItpLZo0SJv1g8AAAAAgMAJ3YUKFZL777/fmtoAAAAAABDIoXvWrFnW1AQAAAAAgECf0w0AAAAAACzq6S5btmya+3H/9ttvGX1KAAAAAABypAyH7n79+nncj4+Pl59++kmio6Nl0KBB3qwbAAAAAACBFbp1y7CUTJ06VTZv3uyNOgEAAAAAkCN4bU73XXfdJQsXLszQY9auXStt27aVkiVLmiHrS5YsSfXcJ5980pwzadIkj/KTJ09K586dJTw83Kys3rNnTzl37lym3wcAAAAAAH4Xuj/55BMpXLhwhh5z/vx5qVGjhuklT8vixYtl48aNJpwnpYF7586dsmLFCrN3uAb5xx9/PMP1BwAAAADA58PLa9Wq5bGQmsPhkOPHj8uff/4p06ZNy3DvuN7ScuTIEXn66adl2bJl0qZNG49ju3fvNnPJf/jhB6lbt64pmzx5stx9990yYcKEFEM6AAAAAAB+G7rbt2/vcT84OFiuv/56adKkiVSqVMmbdZPExETp0qWLWaCtSpUqyY5v2LDBDCl3Bm7VvHlzU6fvv/9e7rvvPq/WBwAAAAAAS0P3iBEjJLuMGzdOcufOLX379k3xuPawFytWzKNMz9dh7nosNZcuXTI3p9jYWNdK7HrzBefr+ur1kX60lT3QTvZAO9kHbWUPtJM90E72QVvZQ7yP2im9r5fh0J1dtmzZIm+++ab8+OOPae4LnhljxoyRUaNGJStfvny55M+fX3xJ56bDHmgre6Cd7IF2sg/ayh5oJ3ugneyDtrKHFdncThcuXPBu6NYh29cKv3r8ypUr4g3ffvutxMTEyE033eQqS0hIkIEDB5oVzH///XeJjIw057jT19cVzfVYaoYNGyYDBgzw6OkuVaqUtGzZ0qyC7gt6lUT/SFq0aCEhISE+qQPSh7ayB9rJHmgn+6Ct7IF2sgfayT5oK3uI91E7OUdMey106wriqdG51W+99ZaZg+0tOpdb52e7a9WqlSnv0aOHud+gQQM5ffq06RWvU6eOKfvmm29MPW699dZUnztv3rzmlpQ2kK+/TP5QB6QPbWUPtJM90E72QVvZA+1kD7STfdBW9hCSze2U3tdKd+i+9957k5Xt2bNHhg4dKkuXLjVbd40ePTpDldT9tPft2+e6f+DAAdm6dauZk6093EWKFEn2prQHu2LFiuZ+5cqVpXXr1vLYY4/J22+/ba5w9OnTRx588EFWLgcAAAAA2HOf7qNHj5qgW61aNTOcW4PynDlzpHTp0hl6ns2bN5styPSmdMi3/j58+PB0P8d//vMfs2r6nXfeabYKu/322+Xdd9/N8HsCAAAAAMDbMrSQ2pkzZ+TVV181e2HXrFlTVq5cKY0aNcr0i+s2Y7rPd3rpPO6ktFd83rx5ma4DAAAAAAA+D93jx483W3jp8O7//ve/KQ43BwAAAAAAmQjdOnc7X758Ur58eTOUXG8pWbRoUXqfEgAAAACAHC3dobtr165e3y8bAAAAAICcLN2he/bs2dbWBAAAAACAHCZTq5cDAAAAAIBrI3QDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYJHcVj0xskdCokM2HTgpMWfjpFjBUKlXtrDkCg7ydbUAAAAAAIRue4vecUxGLd0lx87EucpKRITKiLZR0rpqCZ/WDQAAAADA8HJbB+5ec3/0CNzq+Jk4U67HAQAAAAC+Rei26ZBy7eF2pHDMWabH9TwAAAAAgO8Qum1I53An7eF2p1Fbj+t5AAAAAADfIXTbkC6a5s3zAAAAAADWIHTbkK5S7s3zAAAAAADWIHTbkG4LpquUp7YxmJbrcT0PAAAAAOA7hG4b0n24dVswlTR4O+/rcfbrBgAA8ILEBJED34ps/+TqT70PAOnEPt02pftwT3+kdrJ9uiPZpxsAAMB7dn0mEj1EJPboP2XhJUVajxOJaufLmgGwCUK3jWmwbhEVaVYp10XTdA63DimnhxsAAMBLgfvjrm6bsv5P7LGr5R0/IHgDuCZCt81pwG5QroivqwEAAJCz6BBy7eFOGrgNLQsSiR4qUqmNSHAuH1QQgF0wpxsAAABI6uB6zyHlyThEYo9cPQ8A0kDoBgAAAJI6d8K75wEIWIRuAAAAIKmw4t49D0DAInQDAAAASZVueHWV8mQbtDoFiYTfcPU8AEgDoRsAAABIShdH023BjKTB+3/3W49lETUA10ToBgAAAFKi24HptmDhJTzLtQec7cIApBNbhgEAAACp0WCt24LpKuW6aJrO4dYh5fRwA0gnQjcAAACQFg3YZRv5uhYAbIrh5QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAJBTJCZc/bnrU5ED3/5zHwDgM4RuAACAnGDXZyLT6l/9/dPeInPuEZlU9Wo5AMBnCN0AAAB2p8H6464iZ495lsceu1pO8AYAnyF0AwAA2JkOIY8eIiKOFA7+ryx6KEPNAcBHCN0AAAB2dnC9SOzRNE5wiMQeuXoeACDbEboBAADs7NwJ754HAPAqQjcAAICdhRX37nkAAK8idAMAANhZ6YYi4SVFJCiVE4JEwm+4eh4AINsRugEAAOwsOJdI63H/u5M0eP/vfuuxV88DAGQ7QjcAAIDdRbUT6fiBSMFIz3LtAddyPQ4A8IncvnlZAAAAeJUG63ItRaKXidw7VSS8+NUh5fRwA4BPEboBAAByCmfAjrpXJCTE17UBADC8HAAAAAAA6xC6AQAAAACwCKEbAAAAAACLMKcbAAAAALwkISFB4uPjfV2NgBIfHy+5c+eWuLg48/l7S0hIiOTKlfXFKAndAAAAAJBFDodDjh8/LqdPn/Z1VQLys4+MjJTDhw9LUFCQV5+7UKFC5rmz8ryEbgAAAADIImfgLlasmOTPn9/r4Q+pS0xMlHPnzklYWJgEBwd7LchfuHBBYmJizP0SJUpk+rkI3QAAAACQBTqk2Rm4ixQp4uvqBGTovnz5soSGhnotdKt8+fKZnxq8tW0zO9SchdQAAAAAIAucc7i1hxs5S/7/tWlW5ukTugEAAADACxhSnvMEeaFNGV4OAACQXokJIgfXi5w7IRJWXKR0Q5HgrK9sCwDIuXza07127Vpp27atlCxZ0lxBWLJkieuYdt8PGTJEqlWrJgUKFDDndO3aVY4ePerxHCdPnpTOnTtLeHi4WVmuZ8+eZhI9AACAV+36TGRSVZE594gs7Hn1p97XcgCwidWrV5vslZFV1suUKSOTJk2ytF45mU9D9/nz56VGjRoyderUZMd0pbgff/xRXnzxRfNz0aJFsmfPHmnXrp3HeRq4d+7cKStWrJDPP//cBPnHH388G98FAADI8TRYf9xVJNbz4r/EHrtaTvAG4AXdu3c3gfjJJ59Mdqx3797mmJ7jb0aOHJlivbdu3WrKf//9dwlkPh1eftddd5lbSiIiIkyQdjdlyhSpV6+eHDp0SG666SbZvXu3REdHyw8//CB169Y150yePFnuvvtumTBhgukdBwAAyPKQ8ughuoFMCge1LEgkeqhIpTYMNQeQZaVKlZL58+fLxIkTXatnx8XFybx580wG8le6cviMGTNk4MCBUqFCBV9Xx6/Yak73mTNnzJUSHUauNmzYYH53Bm7VvHlzs0z8999/L/fdd1+Kz3Pp0iVzc4qNjXUNac/KqnRZ4XxdX70+0o+2sgfayR5oJ/sI6LY6uEHk3EmR4NDUzzn3t8hv60RKNxBfCuh2shHaKee1lR7XfZ116yq9ZZY+R61ateS3336TTz75xIzqVfq7Bm4d5u18HaWZZvDgwfLRRx+ZTKO56PXXX5dbbrnF9ZxffvmlDBgwQA4fPiz169eXLl26mHL3un733Xfy/PPPy+bNm6Vo0aLSvn17efXVV800X/e6pfbe9FjFihXl+uuvl+eee87Ux/ka7q+lW6s98cQTsmrVKrOvub6nXr16Sd++fcWpR48eZui7dra+9dZb5j32799fhg0bZp575syZZkXxUaNGmXOdr//HH3+YMu241Tx4++23myHx+pllhdZbn1/bOOmWYen9DtsmdOvVHZ3j/dBDD5n520obSvdLc5c7d24pXLiwOZaaMWPGmAZJavny5T5f5j9p7z78F21lD7STPdBO9hGwbVXj3Wufs/OUyM4vxR8EbDvZDO2Uc9pKM0hkZKRZW0r3i84sDXFXrlwxmUd7jXX9K/X+++/Lgw8+aMKxnuPsNBw6dKh89tlnZrqu9pBrSG3durWZnnvdddeZIPp///d/8u9//1u6desmP/30kwmv6uzZsyacHjhwwIwU1tCtIfWvv/4yQV6HijunAWvw1DzmfN2kNBhroH7hhRekWbNmsmbNGnPxQKcTK/1c9LFadw3mGpw1s2lHqQZqHeXs7DDVczSUa87T6cN6ztNPPy3ffvutNGjQwLTF4sWLTVjXiwg33HCDeYy+T73Y8MUXX5j20JHP+lnoZ5YnTx7JLG3PixcvmmnM2jZJp0TnmNCtH2LHjh3NFYbp06dn+fn0D02v9jjpH4D+kbZs2dIV6H3xHvUPqEWLFhISEuKTOiB9aCt7oJ3sgXayj4BuK+3pnvfAtc97eIFf9HQHbDvZCO2U89pKA6n2JIeFhZlh1pmlr6GBUReHHj16tJw6dcqUa/D8+OOPZePGjeYczSwaaDW86q1Dhw7mvFmzZsm//vUvWbBggTz77LPyn//8R8qVK2fCuKpTp47s379fxo8fLwULFjTPo1N4H374YdPB6aRTdps2bSrvvfeeeT8azvVnalkpb968phe4UaNG8sADD8jLL79sPjdnT3lYWJjrsdoB6qSLZv/8888mXOtFAednoIFcc5++rtZZ66jh19lxWr16dXOBQB9buXJlmTt3rrkwoO9fH6M+/PBD8zx6AUJzXmZp2+ow/8aNGydr29QuQtgudDsD98GDB+Wbb77xaGi9mhQTE+Nxvl590BXN9Vhq9I9Cb0lpA/v6Hz5/qAPSh7ayB9rJHmgn+wjItvrXbSJhha8umpbivO4gkfCSV8/zkzndAdlONkQ75Zy20l5enQargc8Z+jJDn0NvxYsXlzZt2sgHH3xgOh71d+35dR539lBrVtKg63xNzTg6LPuXX34xZfrz1ltv9ahTw4YNzU9nXbdt22ZuOmc86VByzWAaap11S+29Ofey1uOvvPKKeczXX3/tGpUc7Pa5aO+5XijQdbq0B1nDdM2aNV3H9bmqVKliLj446edRtWpV1zn6s0iRIqZX3vkedEi+cxqye2DWzykrbaKP1Tql9DeQ3u9vbjsE7l9//dUMMdAP1p0OL9Dx/lu2bDFXQJQGc/0D0T8uAACALNMg3Xrc1VXKNWB7BO+r/6Mprcf6TeAGkDM8+uij0qdPH/N7Srs9eYsO/dZ51u7zqp0ys3Cb9qw/9thjZui7DpF3pwvEaQ+8zjvXLKe97a+99prpyU8rzDpDb9Iy55xxfQ8a3PXCQdKArcPZfc2noVs/nH379rnu61UIXVZehwGUKFHCjMvX4QA63ECvHjnnaetxHZevV1B0nL426ttvv21Cuv5h6nwHVi4HAABeE9VOpOMHV1cxd982THu4NXDrcQDwIs052gus4bJVq1YphlvNROvWrZPSpUubMs1DurNTv379zH3NSzrn250OUXdXu3Zt2bVrl5QvX95rdR8+fLipn4Zsd1pX7Wl/6qmnXGU63D2rdP64Lt6mPetJe7sl0Pfp1tXx9APSm9J51vq7NtKRI0fMH4hO/terFhrCnbf169e7nkPnKVSqVEnuvPNOswCArlL37rvpWOwEAAAgIzRY99sh0u1zkQ4zrv7st53ADcASOkdat0jWQJx01Wyl86V1MbFBgwaZbZT1PO2M1MW9dE640sXQdNSwnrNnzx7TEzx79myP59G53JqvtPNSO0D1/E8//dTVy54ZOhxcs51zLrmTbiWmGXDZsmWyd+9eefHFF81FgqzSVd51VLQuxqYLrmln7urVq03vvebJgO7pbtKkiZkvkJq0jjlpr7f7/AMAAADL6BDyso18XQsAAeJaizyPHTvWDLHWbcB0NXLdMkwDra5c7hwevnDhQrNCuC6OpvO9dSswHbrupIuS6Wrjunq5zg/XDKa91J06dcpS3XUYuS6GFhcX5yrTYey6gro+t/bg6yrt2uv91VdfZem1dAcqXbVc55Pff//95rPQVc21Y9ZXC2W7C3KkJ9nmcLrqnC5Tr/uA+3L1ct1DT3vrWVDDv9FW9kA72QPtZB+0lT3QTvZAO+W8tnIu2FW2bNksrV6OzNELD5rpNMtlZdG0jLZtenOkT4eXAwAAAACQkxG6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAlT37t0lKChInnzyyWTHevfubY7pOc5z27dvn+pzlSlTxpyvtwIFCkjt2rVlwYIF6arHyJEjXY/VW0REhDRq1EjWrFmT7Nw5c+bILbfcIvnz55eCBQtK06ZNJTo62nX83LlzEhISIvPnz/d43IMPPmie+/fff09W7xdffFGsQugGAAAAAD+QkOiQDfv/lk+3HjE/9X52KFWqlAmoFy9edJXFxcXJvHnz5KabbsrQc40ePVqOHTsmP/30kwnGnTp1kvXr16frsVWqVDGP1duGDRukQoUKcs8998iZM2dc5zz77LPyxBNPmOfdtm2bbNq0SW677Tbp3LmzTJ061ZwTFhYmdevWldWrV3s8v97X9+pefuDAATl48KA0a9ZMrELoBgAAAAAfi95xTG4f94089N5GeWb+VvNT72u51bRHWsPookWLXGX6uwbuWrVqZei5tOc5MjJSbr75ZhOC8+XLJ0uXLk3XY3Pnzm0eq7eoqCgT4LXXeu/eveb4xo0b5fXXX5fXXnvNhO/y5ctL5cqV5eWXX5ZevXrJwIED5fDhw+Zc7f12D9e7d+82FxL0PPdy/T1v3rzSoEEDsQqhGwAAAAB8SIN1r7k/yrEzcR7lx8/EmfLsCN6PPvqozJo1y3V/5syZ0qNHjyw9p4bokJAQuXz5coYfe+nSJVOfQoUKScWKFU3Zf//7X9OLrT3dKQ2Fj4+Pl4ULF7pC9549e0yvuVq1apXcfvvtpkfbPXRruQbu0NBQsQqhGwAAAAB8RIeQj1q6S1IaSO4s0+NWDzV/5JFH5LvvvjNDrfW2bt06U5ZZGrTHjBljhoand+j29u3bTajWm/aQT5gwwQTt8PBwc1x7vMuVKyd58uRJ9tgSJUqY85y94jrkXM9zBmz9eccdd0idOnXkr7/+MsPKlc4Z14BuJUI3AAAAAPjIpgMnk/Vwu9Oorcf1PCtdf/310qZNG5k9e7bpYdbfixYtmuHnGTJkiAnNusjZuHHjZOzYsea50kN7tLdu3WpuW7ZsMUPBH3jgAdm8ebPrHIcjfRcf9PV1TrkzdGu4btKkiel9b9iwoSn/7bff5NChQ5aH7tyWPjsAAAAAIFUxZ+O8el5Wh5j36dPH/O5clCyjBg0aZFY51+BdvHhxs1p4emnPtM7TdtL55EuWLJFJkybJ3LlzzTxx7Y3XXvSkvd06jDw2Ntac46Rh+qOPPpKdO3eaReJ07rrSHm8dVp6YmGjC+a233ipWoqcbAAAAAHykWMFQr56XFa1btzaBVudGt2rVKlPPob3jGpx1MbSMBO7U5MqVy7Wqum75pQurvfPOO8nOmzJlipk/3qFDB4/Q/euvv5pV2HU+tz6Xaty4sen51t5u5zB0K9HTDQAAAAA+Uq9sYSkREWoWTUtp4LTG1siIUHOe1TSU6irfzt9TonO0dfi3uyJFipjVz7PqypUrcvz4cfP72bNnTS/1rl27zJB1pQuePfPMM6Y3XS8O6J7heoHgww8/lLffflsmTpzoUQ8dRq4rk0+ePFmef/55V3m9evUkJiZGPv30Uxk2bJhYjdANAAAAAD6SKzhIRrSNMquUa8B2D97OfmI9rudlB+eiZanR3uGk24j17NlT3n///Sy/9s6dO82CaEqHfeuiadOnT5euXbu6ztGh5tWrV5dp06bJCy+8YC4O6LBxHX6ue3e70xXJ69ev75rP7aRBXMv1vVg9n1sRugEAAADAh1pXLSHTH6ltVil3X1RNe7g1cOtxq+jCaWnROdXu56Z1/u+//57peowcOdLc0jv3XG9OOjdb53OnxH17MHc6pzu7ELoBAAAAwMc0WLeIijSrlOuiaTqHW4eUZ1cPN6xD6AYAAAAAP6ABu0G5IpIThYWFpXrsq6++kkaNGklORegGAAAAAFhqa5LF19zdcMMNkpMRugEAAAAAlirvtv92oCF0AwAAwH4SE0QOrhc5d0IkrLhI6YYiwSlvcQQAvkToBgAAgL3s+kwkeohI7NF/ysJLirQeJxLVzpc1A4BkgpMXAQAAAH4cuD/u6hm4Veyxq+V6HAD8CKEbAAAA9hlSrj3c4kjh4P/KoodePQ8A/AShGwAAAPagc7iT9nB7cIjEHrl6HgD4CUI3AAAA7EEXTfPmeQCQDQjdAAAAsAddpdyb5wGQ7t27S1BQkLmFhIRI2bJlZfDgwRIXF+c6R4+FhobKwYMHPR7bvn178/ikzzV27FiP85YsWWLK02P16tWu+iS9HT9+3JwzcuRIj/LrrrtO7rrrLlmzZo3Hc5UpU8Ycnz9/frLXqVKlijk2e/ZssRqhGwAAAPag24LpKuWS2v+8B4mE33D1PMCOdD2CA9+KbP/k6s9sWp+gdevWcuzYMfntt99k4sSJ8s4778iIESM8ztGAOnz48Gs+l4bzcePGyalTp7JUpz179pg6ud+KFSvmEZqd5evWrZNy5cpJu3bt5MyZMx7PU6pUKZk1a5ZH2caNG02AL1CggGQHQrcNJCQ6ZMP+v+XTrUfMT70PAAAQcHQfbt0WzEgavP93v/VY9uuGPenK+5Oqisy5R2Rhz6s/9X42rMifN29eiYyMNAFVe6+bN28uK1as8DinT58+MnfuXNmxY0eaz6WP1ecaM2ZMlupUrFgx8zzut+Dgf+Jr7ty5XeVRUVEybNgwOXfunOzdu9fjeTp37mx6wA8fPuwqmzlzpinX58gOhG4/F73jmNw+7ht56L2N8sz8rean3tdyAACAgKP7cHf8QCS8hGe59oBrOft0w478aCs8DdXr16+XPHnyeJTfdtttcs8998jQoUPTfHyuXLnk1VdflcmTJ8sff/wh2eHSpUsyb948KVSokFSsWNHjWPHixaVVq1YyZ84cc//ChQvy0UcfyaOPPirZJXuiPTJFg3WvuT8m2xTj+Jk4Uz79kdrSumqS/+AAAADkdBqsK7W5ukq5Lpqmc7h1SDk93MiRW+EFXd0KT//mLfob//zzzyUsLEyuXLliAqz2KE+ZMiXZedp7Xb16dfn222+lUaNGqT7ffffdJzVr1jRD1GfMmJGpOt14440e90uXLi07d+503d++fbupszNI6+86dzs8PDzZc2nAHjhwoDz//PPyySefmKHoWr/sQuj2UzqEfNTSXWl99czxFlGRkis4fYsSAAAA5BgaPsqm/j/9QI7cCs+iv/mmTZvK9OnT5fz582ZOtw677tChQ7LzdBh3165dTW+3zqNOi87rbtasmTz77LOZqpMG+4IFC7ru6yJv7rRH+7PPro4A0HncH374oXTq1ElWrVoldevW9Ti3TZs28sQTT8jatWvN0PLs7OVWhG4/tenASTl25p8VA1MK3npcz2tQrki21g0AAABAztkKTxcUK1++vPldQ2mNGjVMD3XPnj2TnTtq1Ci5+eabzYrkaWncuLEZ1j1s2DCPFc7TS1dR1+HiqdHh7846JyYmmt7r6OhomTRpkpl77k4vInTp0sX0vH///feyePFiyU7M6fZTMWfjvHoeAAAAAD/kZ1vh6dDy5557Tl544QW5ePFisuO62JouqqbnJCSkvbq6bh22dOlS2bBhg2QHnU+eUp2V9m7rgmr33nuv2WIsOxG6/VSxgqFePQ8AAACAH/LDrfAeeOABE2CnTp2a4nHtvT569Kh8/fXXaT5PtWrVzCrhb731VobrEBMTY7b1cr/Fx8e7juv8c2f5r7/+KhMmTJBdu3aZUJ2SypUry19//ZVs+7DsQOj2U/XKFpYSEaFpffXMcT0PAAAAgE354VZ4Ohxbe7PHjx9v5nknVbhwYRkyZIjExV171O3o0aPN8O+M0jnbJUqU8Lht2bLFdVwXVXOW165d2wwZ14sEOuc8NUWKFJF8+fJJdmNOt5/SxdFGtI0yq5TrV819QTXnV1GPs4gaAAAAkEO2wtNVzN0XVdMecA3cFm6FN3v27BTLdbE05/ZgDocjxd5uvV3rucqUKWNWRE+vJk2apPh67kaOHGluThrqY2Njk61c/vvvv6f5PKdPn5bsQOj2Y7odmG4LpquUuy+qFhkRagI324UBAAAAOQRb4eVYhG4/p8FatwXTVcp10TSdw61DyunhBgAAAHKYANgK76677jLbgaVEF2fTW05D6LYBDdhsCwYAAADA7t5///1UVxjXueI5EaEbAAAAAJAtbrjhBgk0rF4OAAAAAIBFCN0AAAAA4AXXWnUbgdmmhG4AAAAAyIKQkBDz88KFC76uCrzM2abONs4M5nQDAAAAQBbkypVLChUqJDExMeZ+/vz5JSiI3YayS2Jioly+fFni4uIkODjYaz3cGri1TbVttY0zi9ANAAAAAFkUGRlpfjqDN7KPw+EwK6Lny5fP6xc7NHA72zazCN0AAAAAkEUa9kqUKCHFihWT+Ph4X1cnoMTHx8vatWulcePGWRoGnpQ+V1Z6uJ0I3QAAAADgJRrSvBHUkH76eV+5ckVCQ0O9Grq9hYXUAAAAAACwCKEbAAAAAACLELoBAAAAALAIc7rdNjyPjY316eR/XZJe6+CP8xDwD9rKHmgne6Cd7IO2sgfayR5oJ/ugrewh3kft5MyPzjyZGkK3iJw9e9b8LFWqlK+rAgAAAACwWZ6MiIhI9XiQ41qxPEA2Uz969KgULFjQZ5vY61USDf2HDx+W8PBwn9QB6UNb2QPtZA+0k33QVvZAO9kD7WQftJU9xPqonTRKa+AuWbKkBAenPnObnm6d2B4cLDfeeKP4A/0j4QttD7SVPdBO9kA72QdtZQ+0kz3QTvZBW9lDuA/aKa0ebicWUgMAAAAAwCKEbgAAAAAALELo9hN58+aVESNGmJ/wb7SVPdBO9kA72QdtZQ+0kz3QTvZBW9lDXj9vJxZSAwAAAADAIvR0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQnc2mjp1qpQpU0ZCQ0Pl1ltvlU2bNqV67uzZsyUoKMjjpo+DtdauXStt27Y1G9zrZ75kyZJrPmb16tVSu3Zts3BD+fLlTdvB/9pK2ynpd0pvx48fz7Y6B5oxY8bILbfcIgULFpRixYpJ+/btZc+ePdd83IIFC6RSpUrm37xq1arJl19+mS31DWSZaSv+O5X9pk+fLtWrV3ftQ9ugQQP56quv0nwM3yf/bye+S/5h7Nix5rPv169fmufxnbJHW832s+8VoTubfPTRRzJgwACzqt6PP/4oNWrUkFatWklMTEyqj9F/qI8dO+a6HTx4MFvrHIjOnz9v2kYvkKTHgQMHpE2bNtK0aVPZunWr+fL/+9//lmXLllle10CX0bZy0iDh/r3SgAFrrFmzRnr37i0bN26UFStWSHx8vLRs2dK0XWrWr18vDz30kPTs2VN++uknE/70tmPHjmyte6DJTFsp/juVvW688UbzP5tbtmyRzZs3S7NmzeTee++VnTt3png+3yd7tJPiu+RbP/zwg7zzzjvmYkla+E7Zp6387nulq5fDevXq1XP07t3bdT8hIcFRsmRJx5gxY1I8f9asWY6IiIhsrCGS0q/H4sWL0zxn8ODBjipVqniUderUydGqVSuLa4eMttWqVavMeadOncq2esFTTEyMaYM1a9akek7Hjh0dbdq08Si79dZbHU888UQ21BAZaSv+O+UfrrvuOsf777+f4jG+T/ZoJ75LvnX27FlHhQoVHCtWrHDccccdjmeeeSbVc/lO2aetZvnZ94qe7mxw+fJlc7WzefPmrrLg4GBzf8OGDak+7ty5c1K6dGkpVarUNa+Qwje0/dzbVekIhrTaFb5Vs2ZNKVGihLRo0ULWrVvn6+oElDNnzpifhQsXTvUcvlP2aSvFf6d8JyEhQebPn29GI+jw5ZTwfbJHOym+S76jo3x01GLS70pK+E7Zp6387XtF6M4Gf/31l/lHt3jx4h7lej+1+aQVK1aUmTNnyqeffipz586VxMREadiwofzxxx/ZVGukh7ZfSu0aGxsrFy9e9Fm9kJwG7bffflsWLlxobvoPcJMmTcx0D1hP/w3T6Re33XabVK1aNcPfKebe+19b8d8p39i+fbuEhYWZdUSefPJJWbx4sURFRaV4Lt8ne7QT3yXf0Qsi+v8Buq5FevCdsk9bVfSz71Vun7wqrkmvhrpfEdU/ksqVK5s5DC+99JJP6wbYkf7jqzf379T+/ftl4sSJ8uGHH/q0boFydVrnvH333Xe+rgq81Fb8d8o39N8xXUNERyN88skn0q1bNzMnP7VAB/9vJ75LvnH48GF55plnzDoWLFyX89qqgZ99rwjd2aBo0aKSK1cuOXHihEe53o+MjEzXc4SEhEitWrVk3759FtUSmaHtl1K76sIN+fLl81m9kD716tUjBGaDPn36yOeff25WnNcFhjLznUrvv5XIvrZKiv9OZY88efKYnTJUnTp1zKJCb775pvkfyaT4PtmjnZLiu5Q9dOqnLmisO9A46chU/fdvypQpcunSJfP/7+74Ttmnrfzte8Xw8mz6h1f/wV25cqWrTIc46P205ve40z8sHaqkQ2ThP7T93NtV6VW49LYrfEt7IfhOWUfXuNMQp8Mqv/nmGylbtuw1H8N3yj5tlRT/nfIN/f8J/R/OlPB9skc7JcV3KXvceeed5nPW/xdw3urWrSudO3c2v6cU4vhO2aet/O575euV3ALF/PnzHXnz5nXMnj3bsWvXLsfjjz/uKFSokOP48ePmeJcuXRxDhw51nT9q1CjHsmXLHPv373ds2bLF8eCDDzpCQ0MdO3fu9OG7CIxVEX/66Sdz06/HG2+8YX4/ePCgOa5tpG3l9Ntvvzny58/vGDRokGP37t2OqVOnOnLlyuWIjo724bsIDBltq4kTJzqWLFni+PXXXx3bt283K14GBwc7vv76ax++i5ytV69eZuXQ1atXO44dO+a6XbhwwXVO0n/71q1b58idO7djwoQJ5js1YsQIR0hIiGkz+Fdb8d+p7Kefv64of+DAAce2bdvM/aCgIMfy5cvNcb5P9mwnvkv+I+mK2Hyn7NtWo/zse8Xw8mzSqVMn+fPPP2X48OFmsQVdQTk6Otq1GMOhQ4fMiuZOp06dkscee8yce91115mect0bkDlb1tL9NHXPbSfdW13pXKzZs2ebPf60rZy0N+iLL76Q/v37m2FjOhzz/fffNytZwr/aSncRGDhwoBw5ckTy589v9nf8+uuvPZ4D3jV9+nTzUxesczdr1izp3r17iv/26ZyrefPmyQsvvCDPPfecVKhQQZYsWZLmgl7wTVvx36nsp8Mru3btav59i4iIMP+OLVu2zOzGoPg+2bOd+C75L75T9nHIz79XQZq8ffLKAAAAAADkcMzpBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGACAHGTlypNSsWTNDjwkKCpIlS5Zk+jW7d+8u7du3z/TjAQDIyQjdAAD4KQ3Dad00YCf17LPPysqVK7O1Dm+++abMnj3ba68JAEBOktvXFQAAACk7duyY6/ePPvpIhg8fLnv27HGVhYWFuX53OBySkJBgytzLs6MO3nw9AAByGnq6AQDwU5GRka5bRESE6Vl23v/ll1+kYMGC8tVXX0mdOnUkb9688t133yUbXv7DDz9IixYtpGjRouY57rjjDvnxxx+9Uge9aeBOOry8SZMm8vTTT0u/fv3kuuuuk+LFi8t7770n58+flx49eph6ly9f3tTd3Y4dO+Suu+4yz6mP6dKli/z1119e+jQBAPANQjcAADY2dOhQGTt2rOzevVuqV6+e7PjZs2elW7duJpBv3LhRKlSoIHfffbcpt9KcOXNM0N+0aZMJ4L169ZIHHnhAGjZsaEJ/y5YtTai+cOGCOf/06dPSrFkzqVWrlmzevFmio6PlxIkT0rFjR0vrCQCA1RheDgCAjY0ePdr0ZKdGg6y7d999VwoVKiRr1qyRe+65x7J61ahRQ1544QXz+7Bhw8yFAQ3hjz32mCnTYerTp0+Xbdu2Sf369WXKlCkmcL/66quu55g5c6aUKlVK9u7dKzfffLNldQUAwEr0dAMAYGN169ZN87j2FmvQ1R5uHR4eHh4u586dk0OHDllaL/de91y5ckmRIkWkWrVqrjIdPq5iYmLMz59//llWrVrlmiOut0qVKplj+/fvt7SuAABYiZ5uAABsrECBAmke16Hlf//9t1lhvHTp0mbud4MGDeTy5cuW1iskJMTjvs4Fdy/T+yoxMdH81AsBbdu2lXHjxiV7rhIlSlhaVwAArEToBgAgB1u3bp1MmzbNzONWhw8f9svFyWrXri0LFy6UMmXKSO7c/O8JACDnYHg5AAA5mA4r//DDD81Ca99//7107txZ8uXLJ/6md+/ecvLkSXnooYfMius6pHzZsmVmtXPdCg0AALsidAMAkIPNmDFDTp06ZXqSdbXwvn37SrFixcTflCxZ0vTKa8DWlc11/rduOaaLvgUH878rAAD7CnI4HA5fVwIAAAAAgJyIS8cAAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBY4/8BXo6/Jy8U2m4AAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 50
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
